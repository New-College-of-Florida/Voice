{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Premise of the algorithm\n",
    "\n",
    "For a stationary time signal $x(t)$, the autocorrelation $r_x(\\tau)$ is defined as: $r_x(\\tau) = \\int x(t)x(t + \\tau)dt$.\n",
    "Considering that this signal has a global maximum at $\\tau = 0$ and periodic, we need to find at what lag ($\\tau$) does $r_x(\\tau)$ have another global maximum. The total lag between these two values will give us the period ($T$) which we can then use to find fundamental frequency as this $ F_0 = \\dfrac{1}{T}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import scipy.signal\n",
    "import scipy.fft\n",
    "import scipy.optimize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "data_dir = \"\"\n",
    "pitch_dir = \"\"\n",
    "\n",
    "minimum_pitch = 60\n",
    "maximum_pitch = 500\n",
    "window_size = None\n",
    "global_absolute_peak = None\n",
    "\n",
    "\n",
    "voice_threshold = 0.4\n",
    "silence_threshold = 0.07\n",
    "candidates = 4\n",
    "octaveCost = 0.06\n",
    "\n",
    "def load_file (name):\n",
    "    y, sr = librosa.load(data_dir + name, sr=None)\n",
    "    return (y, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Find Local Maxima in each frame\n",
    "\n",
    "Since this algorithm requires a constant time signal, we need to analyze a very short frame which will contain the same pitch throughout. We analyze successive frames to come up with our final fundamental frequency value. This way is very robust because analyzing multiple frames helps to minimize any errors which may arise in one or two of many frames. \n",
    "\n",
    "### Find the autocorrelation of a short-term frame\n",
    "1. Multiply the segment with the window function. Boersma proved that Hanning Window, $w(t) = \\frac{1}{2} - \\frac{1}{2} \\cos \\left(\\dfrac{2\\pi t}{T} \\right)$ , showed the best results.\n",
    "2. Find the autocorrelation of $a(t) = x(t) * w(t) $ by first taking discrete fast fourier transform, squaring all the values and then taking the inverse discrete fast fourier transform. \n",
    "3. Finally divide $r_a(\\tau)$ with the autocorrelation of window function $r_w(\\tau) = \\left(1-\\dfrac{\\mid \\tau \\mid}{T} \\right) \\left(\\dfrac{2}{3} + \\dfrac{1}{3} \\cos \\dfrac{2 \\pi \\tau}{T} \\right) + \\dfrac{1}{2 \\pi} \\sin \\dfrac{2 \\pi \\mid \\tau \\mid}{T} $ to get $ r_x(\\tau) $.\n",
    "\n",
    "### Next find the local maxima\n",
    "\n",
    "To find local maxima, we need to do a linear search over $r_x(m\\Delta\\tau)$ and find all such m values where $ r_x((m+1)\\Delta\\tau) < r_x(m\\Delta\\tau)$ and $r_x((m-1)\\Delta\\tau) < r_x(m\\Delta\\tau)$. According to this method our m value should be our local maximum but this is not precise enough that is why we use cubic spline interpolation to get even more accurate local maxima. Instead of searching for local maxima in a linear fasion with a very small increment like 0.00001, I used gradient descent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing (y, sr):\n",
    "    global global_absolute_peak\n",
    "    nyquist_frequency = sr / 2\n",
    "    fft = scipy.fft.fft(y)\n",
    "    for i in range(np.int(0.95 * nyquist_frequency), np.int(nyquist_frequency)):\n",
    "        fft[i] = 0\n",
    "    ifft = np.real(scipy.fft.ifft(fft))\n",
    "    global_absolute_peak = np.max(np.abs(ifft))\n",
    "    return ifft\n",
    "\n",
    "def initialize_min_and_max (song):\n",
    "    global data_dir\n",
    "    \n",
    "    if song[-6] == '1' or song[-6] == '2' or song[-6] == '3':\n",
    "        try:\n",
    "            pitch_data = open(data_dir + 'minmax').readlines()\n",
    "        except FileNotFoundError:\n",
    "            print('Please create a minmax file. Using default values for now')\n",
    "            maximum_pitch = 500\n",
    "            minimum_pitch = 60\n",
    "            return\n",
    "        for each in pitch_data:\n",
    "            if each[0] == song[-6]:\n",
    "                minimum_pitch = int(each.strip().split(' ')[1])\n",
    "                maximum_pitch = (each.strip().split(' ')[2])\n",
    "    else:\n",
    "        maximum_pitch = 500\n",
    "        minimum_pitch = 60\n",
    "        \n",
    "\n",
    "def closest_power_2 (x):\n",
    "    a = 1\n",
    "    while (a < x):\n",
    "        a *= 2\n",
    "    return a\n",
    "\n",
    "c_signal = None\n",
    "\n",
    "def get_sinc_interpolation (x):\n",
    "    global c_signal \n",
    "    nl = np.int(x)\n",
    "    nr = nl + 1\n",
    "    phil = x - nl\n",
    "    phir = 1 - phil\n",
    "    N = min(500, window_size//2)\n",
    "    \n",
    "    # numpy vectorized solution for faster results\n",
    "    \n",
    "    one = c_signal[nl+1:nl+N+1]\n",
    "    two = np.pi * (np.arange(1, one.size+1) + phir - 1)\n",
    "    two = np.multiply(np.divide(np.sin(two), two), (0.5 + 0.5 * np.cos(two/(phir + N))))\n",
    "    two = np.nan_to_num(two, nan=1.0)\n",
    "    \n",
    "    if (nr-N-1 < 0):\n",
    "        difference = np.abs(nr-N-1)\n",
    "        three = np.concatenate((c_signal[max(nr-1, 0):max(nr-N-1, 0):-1], c_signal[1:difference]))\n",
    "    else:\n",
    "        three = c_signal[max(nr-1, 0):max(nr-N-1, 0):-1]\n",
    "    four = np.pi * (np.arange(1, three.size+1) + phil - 1)\n",
    "    four = np.multiply(np.divide(np.sin(four), four), (0.5 + 0.5 * np.cos(four/(phil + N))))\n",
    "    four = np.nan_to_num(four, nan=1.0)\n",
    "    \n",
    "    ans = np.sum(np.multiply(one, two)) + np.sum(np.multiply(three, four))    \n",
    "        \n",
    "    return ans\n",
    "\n",
    "\n",
    "tck = None\n",
    "\n",
    "def cubic_interpolation_init (signal):\n",
    "    global tck\n",
    "    x_points = np.arange(0, signal.size)\n",
    "    tck = scipy.interpolate.interp1d(x_points, -signal, kind=\"cubic\")\n",
    "    \n",
    "def get_hanning_auto_correlate (tau, period):\n",
    "    return (1 - abs(tau)/period) * ((2/3) + (1/3)*np.cos((2 * np.pi * tau)/period)) + (1/(2*np.pi)) * np.sin((2*np.pi*abs(tau))/period)\n",
    "    \n",
    "def get_cubic_interpolation (x):\n",
    "    global tck\n",
    "    try:\n",
    "        return tck(x)\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "def get_gaussian (x, period):\n",
    "        return np.e**(-12 * (x/period - 0.5)**2) / (1-np.e**(-12))\n",
    "\n",
    "def find_max_cubic_interpolation (l, r):\n",
    "    global tck\n",
    "    output = scipy.optimize.brent(get_cubic_interpolation, brack=(l, r), full_output=True, maxiter=500)\n",
    "    return [output[0], -output[1]]\n",
    "\n",
    "def find_max_sinc_interpolation (signal, l, r):\n",
    "    global c_signal\n",
    "    c_signal = -signal\n",
    "    output = scipy.optimize.brent(get_sinc_interpolation, brack=(l, r), full_output=True, maxiter=500)\n",
    "    return [output[0], -output[1]]\n",
    "\n",
    "def small_segment (ifft, start_time, sr):\n",
    "    global window_size\n",
    "    window_size = 3/minimum_pitch * sr\n",
    "    duration = window_size/sr\n",
    "    segment = np.real(ifft[np.int(start_time * sr):np.int(start_time * sr + window_size)])\n",
    "        \n",
    "    local_absolute_peak = np.max(np.abs(segment))\n",
    "    rms = np.real(np.sqrt(np.sum(segment**2)/segment.shape[0]))\n",
    "    segment = np.subtract(segment, rms)\n",
    "    \n",
    "    gaussian = get_gaussian(np.arange(segment.shape[0]), segment.shape[0])\n",
    "    prod = np.multiply(segment, gaussian)\n",
    "    \n",
    "    pad = np.pad(prod, (0, prod.shape[0]//2), 'constant')\n",
    "    pad = np.pad(pad, (0, closest_power_2(pad.shape[0]) - pad.shape[0]), 'constant')\n",
    "    \n",
    "    c_fft = np.real(scipy.fft.ifft(np.square(np.abs(scipy.fft.fft(pad)))))\n",
    "    c_fft = c_fft/c_fft[0]\n",
    "        \n",
    "    gaussian_auto_correlate = np.correlate(gaussian, gaussian, mode='full')\n",
    "    gaussian_auto_correlate = gaussian_auto_correlate[gaussian_auto_correlate.size//2:]\n",
    "    gaussian_auto_correlate = gaussian_auto_correlate/gaussian_auto_correlate[0]\n",
    "        \n",
    "    r_x = np.divide(c_fft[:gaussian.size], gaussian_auto_correlate)\n",
    "    r_x = r_x[:r_x.size//2]\n",
    "    cubic_interpolation_init(r_x)\n",
    "\n",
    "    local_maximi = []\n",
    "    \n",
    "    for i in range(2, min(r_x.size, np.int(np.ceil(1/60*22050)))):\n",
    "        if (r_x[i-2] < r_x[i-1] and r_x[i] < r_x[i-1]):\n",
    "            point, val = find_max_sinc_interpolation(r_x, i-2, i)   #find_max_sinc_interpolation(r_x, i-2, i)\n",
    "            local_maximi.append([point, val])   #find_max_cubic_interpolation(i-2, i) \n",
    "\n",
    "    return (np.array(local_maximi), local_absolute_peak) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Determine possible frequency candidates\n",
    "\n",
    "To determine R we also need to know the global absolute peak (highest peak in the entire signal) and local absolute peak (highest peak in each frame). \n",
    "\n",
    "For each frame we consider 4 candidates. One of them is the silence candidate. The rest of 3 are voiced candidates.\n",
    "All these candidates are represented in a frequency strength pairs (F, R). The unvoiced candidate is assigned frequency 0 and given $ R = \\text{VoicingThreshold} + max \\left(0, 2 - \\dfrac{(\\text{localAbsolutePeak}) / (\\text{globalAbsolutePeak})}{\\text{SilenceThreshold}/(1 + \\text{VoicingThreshold})} \\right) $ \n",
    "\n",
    "Out all the local maxima found for each frame, 3 voiced candidates with the R are considered with $ R = r(\\tau_{max}) - \\text{OctaveCost} \\cdot \\log_2(\\text{MinimumPitch} \\cdot \\tau_{max}) $\n",
    "\n",
    "Default value for voice threshold is 0.4 times global absolute peak and 0.02 times local absolute peak for silence threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " def frame_analysis (local_maximi, local_absolute_peak, sr):\n",
    "    global global_absolute_peak, voice_threshold, silence_threshold, candidates\n",
    "    frequency_strength_pairs = [[0.0, (voice_threshold * global_absolute_peak) + max(0, 2 - (local_absolute_peak/global_absolute_peak)/((silence_threshold * global_absolute_peak)/(1 + (voice_threshold * global_absolute_peak))))]]\n",
    "    c_candidates = candidates\n",
    "    possible_frequency_strength_pairs = []\n",
    "\n",
    "    for i in range(0, local_maximi.shape[0]):\n",
    "        lag = local_maximi[i][0]\n",
    "        F = sr/lag\n",
    "        if (lag > 0 and F < maximum_pitch):\n",
    "            R = min(local_maximi[i][1], 1.0) - octaveCost * math.log2(minimum_pitch * lag * (1/sr))\n",
    "            possible_frequency_strength_pairs.append([F, R])\n",
    "            \n",
    "    possible_frequency_strength_pairs.sort(reverse=True, key=lambda x: x[1])\n",
    "    frequency_strength_pairs += possible_frequency_strength_pairs[:candidates-1]\n",
    "    frequency_strength_pairs.sort(reverse=True, key=lambda x: x[1])\n",
    "    \n",
    "    return np.array(frequency_strength_pairs)\n",
    "\n",
    "def analyze_frame (y, frames, sr): \n",
    "    all_freq_stren_pairs = []\n",
    "    # each frame is the starting sample point, the windows are 24 ms\n",
    "    for i, frame in enumerate(frames): \n",
    "        a, b = small_segment(y, frame, sr)\n",
    "        all_freq_stren_pairs.append(frame_analysis(a, b, sr))\n",
    "        if ((i+1) % 100 == 0):\n",
    "            print(f\"frame {i+1} out of {frames.size}\")\n",
    "    \n",
    "    return np.array(all_freq_stren_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using dynamic programming to efficiently find the lowest cost path\n",
    "\n",
    "Now we have 4 candidates from each frame. Next, we find the least cost path using dynamic programming. The cost is defined as follow: $ cost(\\{p_n\\}) = \\sum\\limits_{n=2}^{\\text{numberOfFrames}} \\text{transitionCost}(F_{n-1, p_{n-1}}, F_{np_n}) - \\sum\\limits_{n=1}^{\\text{numberOfFrames}} R_{np_n} $ \n",
    "\n",
    "Where transition cost is defined to be \n",
    "\n",
    "$ \\text{transitionCost}(F_1, F_2) = $\n",
    "$$\n",
    "\\begin{align}\n",
    "\\begin{cases}\n",
    "0 & \\text{if $F_1 = 0$ and $F_2 = 0$ } \\\\\n",
    "\\text{VoicedUnvoicedCost} & \\text{if $F_1 = 0$ xor $F_2 = 0$} \\\\\n",
    "\\text{OctaveJumpCost} \\cdot \\mid \\log_2 \\dfrac{F_1}{F_2} \\mid & \\text{if $F_1 \\neq 0 $ and $F_2 \\neq 0 $} \\\\\n",
    "\\end{cases}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where all the candidates are defined as $\\{(F_{np_n}, R_{np_n})\\} $\n",
    "\n",
    "And here we define defautl values of VoicedUnvoicedCost and OctaveJumpCost to be 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = None\n",
    "\n",
    "def transition_cost (f1, f2):\n",
    "    voiced_unvoiced_cost = 0.2\n",
    "    octave_jump_cost = 0.2\n",
    "        \n",
    "    if (f1 == 0 and f2 == 0):\n",
    "        return 0\n",
    "    elif ((f1 == 0.0 and f2 != 0.0) or (f1 != 0.0 and f2 == 0.0)):\n",
    "        return voiced_unvoiced_cost\n",
    "    else:\n",
    "        return octave_jump_cost * abs(math.log2(f1/f2))\n",
    "    \n",
    "    \n",
    "def viterbi (all_pairs):\n",
    "    global dp\n",
    "    \n",
    "    for f in range(all_pairs.shape[0]):\n",
    "        for c in range(all_pairs[f].shape[0]):\n",
    "            if f == 0:\n",
    "                dp[f][c] = (-all_pairs[f][c][1], None)\n",
    "            else:\n",
    "                cost, history = (float('inf'), float('inf'))\n",
    "                for p in range(all_pairs[f-1].shape[0]):\n",
    "                    n_cost = dp[f-1][p][0] + transition_cost(all_pairs[f-1][p][0], all_pairs[f][c][0]) - all_pairs[f][c][1]\n",
    "                    if n_cost < cost:\n",
    "                        cost = n_cost\n",
    "                        history = p\n",
    "                dp[f][c] = (cost, history)\n",
    "\n",
    "                \n",
    "def back_track (all_pairs):\n",
    "    global dp\n",
    "    ans = []\n",
    "    c, h = (float('inf'), 0)\n",
    "    for i, each in enumerate(dp[len(dp)-1]):\n",
    "        if (each != np.inf and each[0] < c):\n",
    "            c = each[0]\n",
    "            h = i \n",
    "    for i in range(len(dp)-1, 0, -1):\n",
    "        c = all_pairs[i][h][0]\n",
    "        ans.append(c)\n",
    "        h = dp[i][h][1]\n",
    "    return ans[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating pitch listings\n",
    "\n",
    "Pitches are generated for every 0.01 seconds and saved inside /Akamai/voice/data/pitches/boersma/Scherbaum Mshavanadze/song_name/recording_name.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_store (song_names):\n",
    "    global y, sr, dp\n",
    "    done = 0\n",
    "    for song_name in song_names:\n",
    "        initialize_min_and_max(song_name)\n",
    "        y, sr = load_file(song_name)\n",
    "        y = preprocessing(y, sr)\n",
    "        \n",
    "        duration = y.size/sr\n",
    "        frames = np.arange(0, duration, 0.01)[:-2]\n",
    "        all_pairs = analyze_frame(y, frames, sr)        \n",
    "        dp = np.full((all_pairs.shape[0], candidates), np.inf).tolist()\n",
    "        \n",
    "        viterbi(all_pairs)\n",
    "        f = back_track(all_pairs)\n",
    "        for i in range(len(f)):\n",
    "            f[i] = str(frames[i]) + ' '  + str(f[i])\n",
    "                                    \n",
    "        song_dir = pitch_dir + song_name\n",
    "        song_dir = song_dir[:-4] + \".txt\"\n",
    "        \n",
    "        fout = open(song_dir, \"w+\")\n",
    "        fout.write(\"\\n\".join(str(x) for x in f))\n",
    "        fout.close()\n",
    "        \n",
    "        done += 1\n",
    "        print(f\"{done} done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scherbaum Mshavandaze\n",
    "# parent_data_dir = '/Akamai/voice/data/Scherbaum Mshavanadze/'\n",
    "# parent_pitch_dir = '/Akamai/voice/data/pitches-raw/boersma/Scherbaum Mshavanadze/'\n",
    "\n",
    "# for collection in os.listdir(parent_data_dir):\n",
    "#     if os.path.isdir(f\"{parent_data_dir}{collection}\"):\n",
    "#         parts = []\n",
    "#         for part in os.listdir(f\"{parent_data_dir}{collection}\"):\n",
    "#             if part[-3:] == 'wav':\n",
    "#                 parts.append(part)\n",
    "                \n",
    "#         data_dir = parent_data_dir + collection + '/'\n",
    "#         pitch_dir = parent_pitch_dir + collection + '/'\n",
    "#         create_and_store(parts)\n",
    "        \n",
    "# Teach Yourself Megrelian Songs\n",
    "# parent_data_dir = '/Akamai/voice/data/Teach Yourself Megrelian Songs/'\n",
    "# parent_pitch_dir = '/Akamai/voice/data/pitches-raw/boersma/Teach Yourself Megrelian Songs/'\n",
    "\n",
    "# for collection in os.listdir(parent_data_dir):\n",
    "#     if os.path.isdir(f\"{parent_data_dir}{collection}\"):\n",
    "#         if collection != 'mp3':\n",
    "#             parts = []\n",
    "#             for part in os.listdir(f\"{parent_data_dir}{collection}\"):\n",
    "#                 if part[-3:] == 'wav':\n",
    "#                     parts.append(part)\n",
    "\n",
    "#             data_dir = parent_data_dir + collection + '/'\n",
    "#             pitch_dir = parent_pitch_dir + collection + '/'\n",
    "#             create_and_store(parts)\n",
    "            \n",
    "# Teach Yourself Gurian Songs\n",
    "# parent_data_dir = '/Akamai/voice/data/Teach Yourself Gurian Songs/'\n",
    "# parent_pitch_dir = '/Akamai/voice/data/pitches-raw/boersma/Teach Yourself Gurian Songs/'\n",
    "\n",
    "# for collection in os.listdir(parent_data_dir):\n",
    "#     if os.path.isdir(f\"{parent_data_dir}{collection}\"):\n",
    "#         if collection != 'mp3':\n",
    "#             parts = []\n",
    "#             for part in os.listdir(f\"{parent_data_dir}{collection}\"):\n",
    "#                 if part[-3:] == 'wav':\n",
    "#                     parts.append(part)\n",
    "\n",
    "#             data_dir = parent_data_dir + collection + '/'\n",
    "#             pitch_dir = parent_pitch_dir + collection + '/'\n",
    "#             create_and_store(parts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing and Debugging"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
