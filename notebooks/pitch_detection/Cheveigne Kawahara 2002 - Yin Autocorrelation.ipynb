{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Preliminaries \n",
    "\n",
    "Make equation numbers work in Latex markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "MathJax.Hub.Config({\n",
    "    TeX: { equationNumbers: { autoNumber: \"AMS\" } }\n",
    "});\n",
    "MathJax.Hub.Register.StartupHook(\"TeX AMSmath Ready\", function () {\n",
    "  var AMS = MathJax.Extension['TeX/AMSmath'];\n",
    "  MathJax.InputJax.TeX.postfilterHooks.Add(function (data) {\n",
    "    var jax = data.script.MathJax;\n",
    "    jax.startNumber = AMS.startNumber;\n",
    "    jax.eqLabels = AMS.eqlabels;\n",
    "    jax.eqIDs = AMS.eqIDs;\n",
    "  });\n",
    "  MathJax.InputJax.TeX.prefilterHooks.Add(function (data) {\n",
    "    var jax = data.script.MathJax;\n",
    "    if (jax.startNumber != undefined) {\n",
    "      AMS.startNumber = jax.startNumber;\n",
    "      Object.keys(jax.eqLabels).forEach(function (x) {delete AMS.labels[x]});\n",
    "      Object.keys(jax.eqIDs).forEach(function (x) {delete AMS.IDs[x]});\n",
    "    }\n",
    "  }, 1);\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global constants across different experiments\n",
    "\n",
    "- Minimum frequency to measure: 60Hz\n",
    "- Hop: 0.01s between measurements\n",
    "- Maximum frequency: a default value when the algorithm gets confused\n",
    "- Minimum singing sound volume: 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import isfile\n",
    "\n",
    "# Format of Collection/Song/minmax file:\n",
    "# 1  minf0_v1  maxf0_v1\n",
    "# 2  minf0_v2  maxf0_v2\n",
    "# 3  minf0_v3  maxf0_v3\n",
    "\n",
    "def minmax_f0(file, voice):\n",
    "    if (os.path.isfile(file)):\n",
    "        for line in file:\n",
    "            v, minf0, maxf0 = line.split()\n",
    "            if v == voice:\n",
    "                return (minf0, maxf0)\n",
    "    return (60, 2000)\n",
    "    \n",
    "def min_f0():\n",
    "    return 60\n",
    "\n",
    "def hop_ms():\n",
    "    return 10\n",
    "\n",
    "def max_f0():\n",
    "    return 2000\n",
    "\n",
    "def min_singing_volume():\n",
    "    return 0.05\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main steps\n",
    "\n",
    "The Yin algorithm works in the \"time domain\", i.e., the original audio.\n",
    "\n",
    "- Use the method in the [paper of Cheveigne and Kawahara](https://drive.google.com/file/d/1cM4ZEY6c0F0mZnEkXlizblVEVtM7HtJ6/view?usp=sharing) to detect the (one) fundamental frequency of the voice in the audio\n",
    "    - Step 1. Simple autocorrelation.\n",
    "    - Step 2. Difference function.\n",
    "    - Step 3. Cumulative mean of difference function (CMDF): makes the minimum clearer (removes need for a min period)\n",
    "    - Step 4. Absolute threshold: a threshold for a local min of the CMDF to qualify as a period estimate\n",
    "    - Step 5. Parabolic fit: to find the precise location and value of a local minimum\n",
    "    - Step 6. Best local estimate: compare neighboring estimates to overcome effects of phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "Notes on development.\n",
    "\n",
    "- 7/23/20 \n",
    "    - Finished implementing Yin. The algorithm mistakenly estimates f0 an octave high in seconds 5-6 and 14-15 of the 2nd voice throat mic of Batonebis Nanina. \n",
    "    - I downloaded [Patrice Guyot's Yin implementation](https://github.com/patriceguyot/Yin), which skips steps of the algorithm and does no better in these sections. \n",
    "    - I downloaded the Vamp plugin package for Sonic Visualizer, including Queen's University's Yin and [pYin](https://code.soundsoftware.ac.uk/projects/pyin) implementations. With Yin, Sonic Visualizer's pitches looked the same as my implementation's. With pYin it was much worse, regularly choosing the octave higher.\n",
    "\n",
    "- 8/5/20\n",
    "    - Mauch's pYin implementation does not use Step 6. My Step 6 didn't help.\n",
    "    - What helped was applying a rectangular 1ms filter as a preprocessor.\n",
    "    - I need to make Steps 1-5 the default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Simple autocorrelation\n",
    "\n",
    "The most basic formula for autocorrelation is\n",
    "\n",
    "\\begin{equation}\n",
    "r_t(\\tau) = \\sum^{t+W-1}_{j=t} x_j x_{j+\\tau}\n",
    "\\end{equation}\n",
    "\n",
    "(The paper takes $j$ from $t+1$ to $t+W$.)\n",
    "\n",
    "<font color=\"blue\">To implement this for $j>t+W-\\tau$ we'll get samples from the signal outside the window. We could extend the signal outside the window so that it is periodic with period $W$, but that seems more likely to pick up artifacts. The paper is ambiguous, because in Fig. 1(a) the window seems to be a multiple of the period of the signal. </font>\n",
    "\n",
    "The usual definition of autocorrelation is\n",
    "\n",
    "\\begin{equation}\n",
    "r'_t(\\tau) = \\sum^{t+W-1-\\tau}_{j=t} x_j x_{j+\\tau}\n",
    "\\end{equation}\n",
    "\n",
    "This is the same as Equation (1) if we pad the signal with zeroes outside the window. It has the effect of making $r'_t(\\tau)$ smaller as $\\tau$ increases.\n",
    "\n",
    "The paper simulates this effect by multiplying $r_t(\\tau)$ by ramps of of different slopes and empirically finding the slope that gives the lowest pitch estimate error on a dataset:\n",
    "\n",
    "\\begin{equation}\n",
    "r''_t(\\tau) = r_t(\\tau) (1 - \\tau/\\tau_{max})\n",
    "\\end{equation}\n",
    "if $\\tau < \\tau_{max}$, and $r''_t(\\tau) = 0$ otherwise.\n",
    "\n",
    "The optimal value was $\\tau \\approx 35$ms, which means that only frequencies above $\\sim 30$Hz were measurable and only frequencies above $\\sim 90$Hz were important (since it takes 3 waves to measure a frequency accurately). Picking $\\tau < 35$ms would make it hard to measure frequencies in the speech range. It's not intuitively clear what's wrong with picking $\\tau > 35$ms; maybe the assumption of periodicity is false for the samples of speech in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brute-force computation of the autocorrelation function at every sample point is too slow. \n",
    "\n",
    "Let's use the recursion\n",
    "\n",
    "\\begin{equation}\n",
    "r_t(\\tau) = r_{t-1}(\\tau) + x_{t+W-1} x_{t+W+\\tau-1} - x_{t-1} x_{t+\\tau-1}\n",
    "\\end{equation}\n",
    "\n",
    "to fill the 1D array $\\{r(t, \\tau): \\tau = 0, 1, \\ldots, \\tau_{max}\\}$, for each $t = 0, 1, \\ldots$. \n",
    "\n",
    "If we're using wraparound (turned off by default):\n",
    "- the first term, $x_{t+W} x_{t+W+\\tau}$, wraps around (relative to $t+1$) to $x_{t+W} x_{t+\\tau}$ for $\\tau>0$.\n",
    "- the second term, $x_{t} x_{t+\\tau}$, doesn't wrap around (relative to $t$) as long as $\\tau < W$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define helper functions and a function to calculate f0 at equally spaced sample points in an audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal as ss\n",
    "import scipy.fft\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# initial low-pass filter\n",
    "def lowpass_filter(y):\n",
    "    return ss.convolve(y, np.ones(48), mode='same', method='auto')\n",
    "\n",
    "# autocorrelation function - Eqn (1) above - using recursion (4) above\n",
    "#  - creates/updates the array {r_t(tau): tau = 0, 1, ..., W}\n",
    "#  - returns:\n",
    "#    - if acf = None: returns the array {r_0(tau): tau = 0, 1, ..., W}\n",
    "#    - if acf != None: returns None\n",
    "#  - y is a sequence of audio samples\n",
    "#  - creates \n",
    "#  - the function operates on the subsequence y[t+1:t+W], with wraparound if wrap=true\n",
    "def acf1_from_scratch(y, W, t=0):\n",
    "    return np.correlate(y[t:t+2*W-1], y[t:t+W])\n",
    "    \n",
    "#\n",
    "# - Does something only if acf.size >= W and t>0\n",
    "def acf1_incremental(y, W, t, acf):\n",
    "    if t <= 0 or acf.size < W:\n",
    "        return None\n",
    "    try:\n",
    "        return acf + y[t+W-1]*y[t+W-1:t+2*W-1] - y[t-1]*y[t-1:t+W-1]\n",
    "    except ValueError:\n",
    "        print(acf.size, t, W, y.size)\n",
    "            \n",
    "# returns a ramp used to dampen the autocorrelation function\n",
    "def get_ramp(tau_max):\n",
    "    return 1-np.array(range(tau_max,))/tau_max\n",
    "\n",
    "# This relationship is from the paper.\n",
    "# This is ok even if later we specify our own minf0.\n",
    "def W_ms():\n",
    "    return 1000//min_f0()\n",
    "\n",
    "# This relationship is from the paper.\n",
    "def W_ms(file=None, voice=None):\n",
    "    if file != None:\n",
    "        return 1000//minmax_f0(file, voice)[0]\n",
    "    else:\n",
    "        return 1000//min_f0()\n",
    "\n",
    "# returns a batch of autocorrelation functions indexed by (t, tau)\n",
    "def get_acf_in_range(y, W, start, end):\n",
    "    acf = np.ndarray((end-start, W))\n",
    "    \n",
    "    for t in range(start, end): \n",
    "        if t==start:\n",
    "            acf[t-start,:] = acf1_from_scratch(y, W, t)\n",
    "        else:\n",
    "            acf[t-start,:] = acf1_incremental(y, W, t, acf[t-start-1,:])\n",
    "            \n",
    "    return acf\n",
    "\n",
    "# finds f0 from an autocorrelation function\n",
    "# - for now, finds the second strongest wavelength of the acf, after 0:\n",
    "#   - Assume f0<min_f0, so wavelength >sr/min_f0\n",
    "#   - Find argmax(smooth_acf(tau)), tau > sr/min_f0\n",
    "# - acf: a list of acf(tau) for tau = 0,..., W-1\n",
    "def get_f0(acf, sr):\n",
    "    return sr//(sr//max_f0() + np.argmax(acf[sr//max_f0():]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Difference function\n",
    "\n",
    "The \"signal model\" for a periodic signal of period $T$\n",
    "\n",
    "\\begin{equation}\n",
    "x_t - x_{t+T} = 0,~\\forall T\n",
    "\\end{equation}\n",
    "\n",
    "suggests minimizing the sum of squares of differences \n",
    "\n",
    "\\begin{align}\n",
    "d_t(\\tau) & = \\sum^{t+W-1}_{j=t} (x_j - x_{j+\\tau})^2 \\\\\n",
    "          & = r_t(0) + r_{t+\\tau}(0) - 2r_t(\\tau)\n",
    "\\end{align}\n",
    "\n",
    "It turns out $r_t(\\tau)$ is sensitive to changes in amplitude and $d_t(\\tau)$ isn't.\n",
    "\n",
    "#### Note\n",
    "\n",
    "We need only compute $d_t(\\tau)$ for $t = $ a multiple of `hop_ms()`, or every $sr/100$ samples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Difference function normalized by the mean so far\n",
    "\n",
    "The normalized difference function is\n",
    "\n",
    "\\begin{equation}\n",
    "d'_t(\\tau) = \n",
    "\\begin{cases}\n",
    "1, & \\text{if $\\tau=0$} \\\\\n",
    "d_t(\\tau) \\bigg/ \\frac{\\sum^{\\tau}_{j=1} d_t(j)}{\\tau}, & \\text{otherwise}\n",
    "\\end{cases}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Threshold for minimum of difference function\n",
    "\n",
    "Choose the smallest local minimum value of $d'$ below a threshold.\n",
    "\n",
    "The paper chooses a threshold of $0.1$.\n",
    "\n",
    "I've modified that to a threshold of $min(0.1,2*{\\text global min})$ because the Yin algorithm picks up higher frequencies from the larynx mic during a glissando.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_function(r, times):\n",
    "    W = r.shape[1]\n",
    "    T = r.shape[0]\n",
    "    d = np.zeros((times.size, W))\n",
    "    i = 0\n",
    "    for t in times:\n",
    "        d[i,:] = r[t,0] + r[t:t+W,0] - 2*r[t,:]\n",
    "        i += 1\n",
    "    return d    \n",
    "\n",
    "# fancier but covers any errors\n",
    "def fancy_normalize_diff(d):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        normd = np.true_divide(d*np.arange(W), np.cumsum(d, axis=1))\n",
    "        normd[ ~ np.isfinite( normd )] = 1  # -inf inf NaN\n",
    "    return normd\n",
    "\n",
    "# fast enough?\n",
    "def normalize_diff(d):\n",
    "    W = d.shape[1]\n",
    "    csum = np.cumsum(d, axis=1)\n",
    "    csum[:,0] = 1\n",
    "    normd = np.true_divide(d*np.arange(1,W+1), csum)\n",
    "    normd[:,0] = 1 \n",
    "    return normd\n",
    "\n",
    "def tau_min_threshold():\n",
    "    return 0.1\n",
    "\n",
    "def tau_min_mult_threshold():\n",
    "    return 2\n",
    "\n",
    "# finds f0 from a \"difference autocorrelation function\"\n",
    "# - for now, finds the first \"low\" local minimum in the normalized difference function of the acf:\n",
    "# - d: a list of d(tau) for tau = 0,..., W-1\n",
    "def get_f0(d, sr):\n",
    "    tau_min = np.argmin(d[:])\n",
    "    d_thresh = np.argmax(d<tau_min_threshold())\n",
    "    return sr/(d_thresh if d[d_thresh]<min(tau_min_threshold(),tau_min_mult_threshold*tau_min) else tau_min)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Fit a parabola to each local minimum of $d'$\n",
    "\n",
    "Find either\n",
    "- the smallest index $\\tau$ of a local minimum whose fitted parabola takes values smaller than $0.1$, if such a local minimum exists\n",
    "- the index $\\tau$ of the global minimum of $d'$ (the local minimum whose fitted parabola takes the lowest value)\n",
    "\n",
    "The abscissa of the minimum of the fitted parabola is biased because of the normalization of $d'$:\n",
    "- the index of a local minimum of $d'$ is less than or equal to the index of the corresponding local minimum of $d$, but in a pathological (and possibly unrealistic) case it can much smaller\n",
    "- simple math shows it can't be bigger\n",
    "\n",
    "Given the $\\tau'$ of the best local minimum of $d'$:\n",
    "- search for $\\tau>\\tau'$ of the corresponding local minimum of $d$\n",
    "- fit $d(\\tau)$ locally to a parabola and return the abscissa of the minimum value of the parabola\n",
    "\n",
    "The parabola $ax^2 + bx + c$ goes through the points $(-1, x)$, $(0, c)$, and $(1, y)$, where $x = a-b+c$ and  and $y = a+b+c$, and reaches its minimum at \n",
    "$$\\tau = \\frac{x-y}{2*(x+y-2c)}.$$ \n",
    "The minimum value is\n",
    "$$-\\frac{b^2}{4a} + c = -\\frac{(x-y)^2}{8(x+y-2c)} + c.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Code for Steps 1-6 is at the bottom of the notebook.\n",
    "\n",
    "Step 6 was hard to develop, made the process run slower, and didn't seem to improve accuracy.\n",
    "\n",
    "What follows are steps 1-5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## These functions return arrays with indices 0 to W-1 representing tau = 0 to W-1 \n",
    "\n",
    "# the argmins of the parabolas through each group of three consecutive points in the array\n",
    "def quadratic_argmins(a):\n",
    "    W = a.size\n",
    "    argmins = np.r_[0, np.true_divide(a[:-2]-a[2:],a[:-2]+a[2:]-2*a[1:-1])/(2) + np.arange(1,a.size-1), W-1]\n",
    "    return argmins\n",
    "\n",
    "# the mins of the parabolas through each group of three consecutive points in the array\n",
    "def quadratic_mins(a):\n",
    "    return np.r_[1, -np.true_divide((a[:-2]-a[2:])**2,8*(a[:-2]+a[2:]-2*a[1:-1])) + a[1:-1], 1]\n",
    "\n",
    "def local_mins(a):\n",
    "    #return np.r_[False,a[1:] < a[:-1]] & np.r_[a[:-1] < a[1:],False]\n",
    "    return np.r_[False, (a[1:-1] < a[:-2]) & (a[1:-1] <= a[2:]), False]\n",
    "\n",
    "# finds the best index from normd and uses it to find the best abscissa from d \n",
    "def get_period(y_window, normd, d, minPeriod=0, maxPeriod=None):\n",
    "    if max(y_window) < min_singing_volume():\n",
    "        return 0\n",
    "    qnormd = quadratic_mins(normd)\n",
    "    qnormd[~local_mins(normd)] = 1\n",
    "    \n",
    "    if maxPeriod == None:\n",
    "        maxPeriod = qnormd.size\n",
    "    else:\n",
    "        maxPeriod = min(maxPeriod+1, qnormd.size)\n",
    "    \n",
    "    # smallest local min tau whose parabola goes under 0.1\n",
    "    # argmax of Trues and Falses finds the first True\n",
    "    tau_min = minPeriod + np.argmax(qnormd[minPeriod:maxPeriod]<tau_min_threshold()) \n",
    "    \n",
    "    if qnormd[tau_min] >= tau_min_threshold():  \n",
    "        tau_min = minPeriod + np.argmin(qnormd[minPeriod:maxPeriod])\n",
    "\n",
    "    # cases:\n",
    "    # - qnormd[tau_min] < 1 because it's a local minimum or minimum at minPeriod or maxPeriod \n",
    "    # - tau_min = first non-local-min >= minPeriod, because there is no value < 1            \n",
    "\n",
    "    # a local min of normd must occur at or earlier than the corresponding local min of d\n",
    "    #! this should be vectorized\n",
    "    for i in range(tau_min, d.size-1):\n",
    "        if d[i+1] > d[i]:\n",
    "            break\n",
    "    return quadratic_argmins(d)[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# reff0 will be used to constrain the range of periods yin searches in\n",
    "\n",
    "def yin1To5(y, sr, minf0, maxf0):\n",
    "    # initialize variables\n",
    "    # W, start, end, last_t are multiples of hop\n",
    "    hop = hop_ms()*sr//1000 # assume there's no rounding\n",
    "    W = W_ms() * sr // 1000\n",
    "    W = W + hop - W%hop\n",
    "    \n",
    "    start = 0\n",
    "    batch_size = hop*100\n",
    "    end = min(y.size-2*W, start + batch_size)\n",
    "    end = end - end%hop\n",
    "    last_t = end-W\n",
    "    batches = 200\n",
    "    f0_arr = np.ndarray(max(0,min(y.size,batches*batch_size-W)//hop))\n",
    "    \n",
    "    # range of periods to search\n",
    "    minPeriod = sr//maxf0;\n",
    "    maxPeriod = (sr+minf0-1)//minf0;\n",
    "\n",
    "    for b in range(batches):\n",
    "        print(\"Batch \" + str(b) + \" from t=\" + str(start) + \" to \" + str(end))\n",
    "        # Compute autocorrelation and difference functions for a range of t \n",
    "        acf1=get_acf_in_range(y, W, start, end)\n",
    "        diff_times = np.arange(0,last_t-start,hop)\n",
    "        d = diff_function(acf1, diff_times)        \n",
    "        normd = normalize_diff(d)\n",
    "\n",
    "        # Get f0 values\n",
    "        for i in range(diff_times.size):\n",
    "            t = diff_times[i]+start\n",
    "            #print(\"Time \" + str())\n",
    "            est_period = get_period(y[t:t+W], normd[i,:], d[i,:], minPeriod, maxPeriod)\n",
    "            if est_period*max_f0() < sr:\n",
    "                f0_arr[i+(start//hop)] = 0\n",
    "            else:\n",
    "                f0_arr[i+(start//hop)] = sr/est_period\n",
    "\n",
    "        if end == y.size-2*W:\n",
    "            break\n",
    "        start = end-W\n",
    "        end = min(y.size-2*W, end + batch_size)\n",
    "        last_t = end-W\n",
    "        \n",
    "    return f0_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postprocessing\n",
    "\n",
    "1. A simple step to correct the pitch when Yin picks 2f0, f0/2, or f0/3.\n",
    "2. Force correction if the pitch is outside the main octave.\n",
    "\n",
    "Fix the file in place and remove the backup except in debug mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import rename, remove\n",
    "from os.path import join, splitext\n",
    "from queue import Queue\n",
    "\n",
    "qSize=10\n",
    "numQs = 3\n",
    "variance_tolerance = 100\n",
    "octaveRange = 1.0\n",
    "binsPerOctave = 12\n",
    "rangeInBins = int(octaveRange*binsPerOctave)\n",
    "minTessitura=64\n",
    "maxTessitura=1024\n",
    "octaves=4\n",
    "\n",
    "def rolling_window_1d(a, window, hop):\n",
    "    shape = ((a.shape[0] - window + hop)//hop, window)\n",
    "    strides = (a.strides[0]*hop, a.strides[0])\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)\n",
    "\n",
    "def prevf(f, idx):\n",
    "    qs = rolling_window_1d(f[idx-qSize*numQs:idx], qSize, qSize)\n",
    "    means = np.mean(qs, axis=1)\n",
    "    variances = np.var(qs, axis=1)\n",
    "    retval = f[idx]\n",
    "    if np.min(variances) < variance_tolerance:\n",
    "        retval = means[np.argmin(variances)]\n",
    "    return retval\n",
    "\n",
    "def isClose(prevf, f, minf0):\n",
    "    tolerance = 0.1\n",
    "    if prevf <= minf0:\n",
    "        return False\n",
    "    if abs((f-prevf)/prevf) < 0.1:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def f0range(hist, binEdges):\n",
    "    integral = np.sum(hist[:rangeInBins])\n",
    "    maxIntegral = integral\n",
    "    imax=0\n",
    "    i = 1\n",
    "    while i < hist.size-rangeInBins:\n",
    "        integral += hist[i+rangeInBins] - hist[i-1]\n",
    "        if integral > maxIntegral:\n",
    "            maxIntegral = integral\n",
    "            imax = i\n",
    "        i += 1\n",
    "    return (binEdges[imax], binEdges[imax+rangeInBins])\n",
    "\n",
    "def getF0Range(rawfile, debug=False):\n",
    "    t, f0Est = np.loadtxt(rawfile, unpack=True)\n",
    "    \n",
    "    # histogram of f0 estimates\n",
    "    maxf0Est = np.max(f0Est)\n",
    "    binEdges = np.rint(np.geomspace(minTessitura, maxTessitura, num=binsPerOctave*octaves+1)).astype(int)\n",
    "    f0RawHist, bin_edges  = np.histogram(f0Est, bins=binEdges, range=(0, maxf0Est))\n",
    "    return f0range(f0RawHist, binEdges)\n",
    "    \n",
    "def postprocess(file, debug=False):\n",
    "    rawfile = splitext(file)[0] + '.raw.txt'\n",
    "    rename(file, rawfile)\n",
    "    t, f0Est = np.loadtxt(rawfile, unpack=True)\n",
    "    \n",
    "    # adjust to closest pitch in range\n",
    "    idx = numQs*qSize\n",
    "    for i in range(idx, f0Est.size):\n",
    "        if i%48000 == 0:\n",
    "            print(i)\n",
    "        prev = prevf(f0Est, i)\n",
    "        f = f0Est[i]\n",
    "        if isClose(prev, f/2, minf0):\n",
    "            f0Est[i] = f/2\n",
    "        elif isClose(prev, 2*f, minf0):\n",
    "            f0Est[i] = 2*f\n",
    "        elif isClose(prev, 3*f, minf0):\n",
    "            f0Est[i] = 3*f\n",
    "\n",
    "    np.savetxt(file, np.column_stack((t, f0Est)), fmt='%6.2f %7.2f')\n",
    "    f0Hist = np.histogram(f0Est, bins=200, range=(0, maxf0Est))[0]\n",
    "    if debug:\n",
    "        print(\"Saving un-postprocessed file:\\n\" + rawfile)\n",
    "        print(\"Plotting before/after histograms\")\n",
    "        plt.plot(np.arange(0, maxf0Est, maxf0Est/200.), f0RawHist, '.')\n",
    "        plt.plot(np.arange(0, maxf0Est, maxf0Est/200.), f0Hist, '.')\n",
    "        plt.show()\n",
    "    else:\n",
    "        os.remove(rawfile)\n",
    "    \n",
    "### Testing ###\n",
    "test=False\n",
    "if test:\n",
    "    file = join('/Akamai/voice/data/', 'pitches/yin','Scherbaum Mshavanadze/')\n",
    "    file = join(file, 'GVM009_BatonebisNanina_Tbilisi_Mzetamze_20160919')\n",
    "    file = join(file, 'GVM009_BatonebisNanina_Tbilisi_Mzetamze_20160919_AHDS1M.txt')\n",
    "    postprocess(file, min_f0(), max_f0(), True)\n",
    "    \n",
    "    rawfile = splitext(file)[0] + '.raw.txt'\n",
    "    t, f0 = np.loadtxt(file, unpack=True)\n",
    "    t, f0raw = np.loadtxt(rawfile, unpack=True)\n",
    "    plt.rcParams['figure.figsize'] = [100, 5]\n",
    "    plt.plot(t,f0,'.')\n",
    "    plt.plot(t,f0raw,'.')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data.\n",
    "\n",
    "#### Create an html parser to read the directory manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser\n",
    "\n",
    "new_track = False\n",
    "class MyHTMLParser(HTMLParser):\n",
    "    def __init__ (self):\n",
    "        HTMLParser.__init__(self)\n",
    "        self.data = []\n",
    "\n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        new_track = True\n",
    "        if tag == \"track-wrap\":\n",
    "            for key, val in attrs:\n",
    "                if key == \"title\":\n",
    "                    self.data.append(val)\n",
    "        if tag == \"video\":\n",
    "            self.data.append(\"video\")\n",
    "        if tag == \"source\":\n",
    "            for key, val in attrs:\n",
    "                if key == \"src\":\n",
    "                    self.data.append(os.path.basename(val))\n",
    "\n",
    "    def handle_endtag(self, tag):\n",
    "        if tag == \"track-wrap\" or tag == \"video\":\n",
    "            new_track = False\n",
    "\n",
    "    def handle_data(self, data):\n",
    "        pass\n",
    "    \n",
    "    def get_data (self):\n",
    "        return zip(self.data, self.data[1:] + self.data[:1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the Yin algorithm on 'throat' and 'headset' files in all song directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from os import listdir\n",
    "from os.path import isdir, join, splitext, exists\n",
    "\n",
    "root = '/Akamai/voice/data/'\n",
    "alg = 'pitches/yin'\n",
    "collections = ['Scherbaum Mshavanadze/']\n",
    "for coll in collections:\n",
    "    songdirs = [d for d in listdir(join(root,coll)) if isdir(join(root, coll, d))]\n",
    "    for sd in songdirs: \n",
    "        files = dict()\n",
    "        html= open(join(root, coll, sd, 'page.txt')).read()\n",
    "        parser = MyHTMLParser()\n",
    "        parser.feed(html)\n",
    "        files['throat'] = [f[1] for f in \\\n",
    "                           list(filter(lambda x: re.search(\"Throat microphone [0-9]+\", x[0]), parser.get_data()))]\n",
    "        files['headset'] = [f[1] for f in \\\n",
    "                            list(filter(lambda x: re.search(\"Headset microphone [0-9]+\", x[0]), parser.get_data()))]\n",
    "        \n",
    "        for mic in files:\n",
    "            for f in files[mic]:\n",
    "                f0dir = join(root, alg, coll, sd)\n",
    "                os.makedirs(f0dir, exist_ok=True)\n",
    "                f0file = join(f0dir, splitext(f)[0] + '.txt')\n",
    "                f0rawfile = join(f0dir, splitext(f)[0] + '.raw.txt')\n",
    "                data_path = join(root, coll, sd, f)\n",
    "                y, sr = librosa.load(data_path, sr=None)\n",
    "                needraw = not exists(f0rawfile)\n",
    "                if needraw:\n",
    "                    print(\"Working on audio file: \", f, \"sr = \", sr)\n",
    "                    f0_arr = yin1To5(lowpass_filter(y), sr, min_f0(), max_f0())\n",
    "                    x = np.arange(0, f0_arr.size/100,0.01)\n",
    "                    np.savetxt(f0rawfile, np.column_stack((x, f0_arr)), fmt='%6.2f %7.2f')\n",
    "                    print(\"Yin raw f0 estimates written to: \", f0rawfile)\n",
    "                else:\n",
    "                    print(\"Skipping raw estimate, raw file already exists: \", f0rawfile)\n",
    "\n",
    "                if needraw or not exists(f0file):\n",
    "                    minf0, maxf0 = getF0Range(f0rawfile, True)\n",
    "                    print(\"Voice range: \", minf0, maxf0)\n",
    "                    f0_arr = yin1To5(lowpass_filter(y), sr, minf0, maxf0)\n",
    "                    x = np.arange(0, f0_arr.size/100,0.01)\n",
    "                    np.savetxt(f0file, np.column_stack((x, f0_arr)), fmt='%6.2f %7.2f')\n",
    "                    print(\"Yin final f0 estimates written to: \", f0file)\n",
    "                else:\n",
    "                    print(\"Skipping final estimate, file already exists: \", f0file)\n",
    "\n",
    "                ### Testing ###\n",
    "                test=True\n",
    "                if test:\n",
    "                    t, f0 = np.loadtxt(f0file, unpack=True)\n",
    "                    plt.rcParams['figure.figsize'] = [100, 5]\n",
    "                    plt.plot(t,f0,'.')\n",
    "                    plt.ylim((100,400))\n",
    "                    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for testing, choose and write a section of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile\n",
    "segment_dir = os.path.splitext(dirs[0]+dirs[1]+file)[0]\n",
    "print(segment_dir)\n",
    "duration=1 # seconds\n",
    "\n",
    "for offset in [5,14]: \n",
    "    file_seg = segment_dir + '/' + str(offset) + '-' + str(offset+duration) + '.wav'\n",
    "    soundfile.write(file_seg, y_master[offset*sr:(offset+duration)*sr].T, sr)\n",
    "\n",
    "# Listen to song segments\n",
    "\n",
    "%matplotlib inline\n",
    "import IPython.display as ipd\n",
    "\n",
    "for offset in [5, 14]:\n",
    "    ipd.display(ipd.Audio(y_master[offset*sr:(offset+duration)*sr], rate=sr))\n",
    "    \n",
    "y = y_master[14*sr:(14+duration)*sr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph f0 in a given time range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sr, hop)\n",
    "plt.rcParams['figure.figsize'] = [20, 5]\n",
    "st = 1400*hop\n",
    "end = 1500*hop\n",
    "plt.plot(np.arange(st, end, hop),f0_arr[st//hop:end//hop],'.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listen to song\n",
    "\n",
    "%matplotlib inline\n",
    "import IPython.display as ipd\n",
    "\n",
    "ipd.Audio(y[0:9600000], rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Code for Steps 1-6.\n",
    "\n",
    "I step 6 and the needed alterations to steps 1-5 here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6. Best Local Estimate\n",
    "\n",
    "When the sound is non-stationary the estimate of the period can be poor when the signal is in the wrong phase. We want to search for the best estimate over nearby phases in the same period. The paper suggests searching over the maximum period $T_{max}$. \n",
    "\n",
    "We're seeing this with glissando (a slide from one note to another).\n",
    "\n",
    "For us this means $T_{max} = 1/60$s. That's about $1/120$s or 400 samples to search on either side \n",
    "\n",
    "At each $t$ we'll \n",
    "- estimate the period $T_{\\theta}$ as in Steps 3-5 for each $\\theta$ in a neighborhood of $t$\n",
    "- find the argmin $\\theta_0$ of $d'$ over these estimates: ${argmin}_{\\theta} d'_{\\theta}(T_{\\theta})$\n",
    "- search over $\\tau$ near $T_{\\theta_0}$ (according to the paper, within 20% of $T_{\\theta_0}$) for a minimum of $d'_t(\\tau)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## These functions return arrays with indices 1 to W-2 representing tau = 1 to W-2, and \n",
    "## dummy values added for tau = 0, W-1\n",
    "\n",
    "# the argmins of the parabolas through each group of three consecutive points in each row \n",
    "def quadratic_argmins(a):\n",
    "    W = a.shape[1]\n",
    "    zeros = np.zeros((a.shape[0],1))\n",
    "    ones = np.ones((a.shape[0],1))\n",
    "    argmins = np.true_divide(a[:,:-2]-a[:,2:],a[:,:-2]+a[:,2:]-2*a[:,1:-1])/(2) + np.arange(1,a.shape[1]-1)\n",
    "    return np.hstack((zeros,argmins,ones*(W-1)))\n",
    "\n",
    "# the local minima of the parabolas through each group of three consecutive points in the array\n",
    "def quadratic_mins(a):\n",
    "    ones = np.ones((a.shape[0],1))\n",
    "    mins = np.maximum(0,-np.true_divide((a[:,:-2]-a[:,2:])**2,8*(a[:,:-2]+a[:,2:]-2*a[:,1:-1])) + a[:,1:-1])\n",
    "    return np.hstack((ones, mins, ones))\n",
    "\n",
    "def local_mins(a):\n",
    "    falses = np.zeros((a.shape[0],1), dtype=bool)\n",
    "    return np.hstack((falses, (a[:,1:-1] < a[:,:-2]) & (a[:,1:-1] <= a[:,2:]), falses))\n",
    "\n",
    "def is_local_min(a, i):\n",
    "    return ((a[i] < a[i-1]) and (a[i] <= a[i+1])) or ((i == 0) and a[0] < a[1])\n",
    "\n",
    "# finds the best index from normd and uses it to find the best abscissa from d \n",
    "def get_all_periods(qnormd, debug_times):\n",
    "    \n",
    "    # smallest local-min period whose parabola goes under 0.1, or global min period\n",
    "    first_small_or_zero = np.argmax(qnormd<tau_min_threshold(), axis=1) # index of first True\n",
    "    is_small = qnormd[np.arange(len(qnormd)), first_small_or_zero]<tau_min_threshold()\n",
    "    tau_min = np.where(is_small,first_small_or_zero, np.argmin(qnormd,axis=1))\n",
    "    if debug_times is not None:\n",
    "        for t in debug_times:\n",
    "            print(\"Period logic: \", first_small_or_zero[t], is_small[t], tau_min[t])\n",
    "    \n",
    "    return tau_min\n",
    "\n",
    "# turns 1-d array into read-only rows of windows into array, one every hop elements\n",
    "def rolling_window_1d(a, window, hop):\n",
    "    shape = ((a.shape[0] - window + hop)//hop, window)\n",
    "    strides = (a.strides[0]*hop, a.strides[0])\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides, writeable=False)\n",
    "\n",
    "# finds the location of the minimum of d_t(tau) near the best local estimate \n",
    "def get_desired_periods(d_slice, T_theta_0):\n",
    "    tau_window = .2 # 20% of T_theta_0\n",
    "    d_max = np.max(d_slice)\n",
    "        \n",
    "    # find argmin d_t[T] for T within 20% of \\T_theta_0\n",
    "    tau_args = np.arange(d_slice.shape[1])\n",
    "    t_args = np.arange(d_slice.shape[0])\n",
    "    nearby = np.logical_and(tau_args>=T_theta_0[:,None]*(1-tau_window), tau_args<=T_theta_0[:,None]*(1+tau_window))\n",
    "    d_nearby = np.where(nearby, d_slice, d_max)\n",
    "    d_nearby_arg = np.argmin(d_nearby, axis=1)\n",
    "    \n",
    "    # return argmin of fitted parabola if the estimate is a local min; otherwise, the estimate\n",
    "    are_local_mins = local_mins(d_slice)[t_args,d_nearby_arg]\n",
    "    return np.where(are_local_mins, quadratic_argmins(d_slice)[t_args,d_nearby_arg], d_slice[t_args, d_nearby_arg])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Loop for Steps 1-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yin1To6(y, sr):\n",
    "    # initialize variables\n",
    "    # W, start, end, last_t are multiples of hop\n",
    "    hop = hop_ms()*sr//1000 # assume there's no rounding\n",
    "    W = W_ms() * sr // 1000\n",
    "    W = W + hop - W%hop\n",
    "    t_window = sr//min_f0() # to search for best local estimate\n",
    "    while (t_window//2 >= hop):\n",
    "        print(\"Window too small. Window: \" + str(t_window) + \", Hop: \" + str(hop))\n",
    "        t_window = t_window//2\n",
    "    start = 0\n",
    "    batch_size = hop*100\n",
    "    end = min(y.size-2*W, start + batch_size)\n",
    "    end = end - end%hop\n",
    "    last_t = end-W\n",
    "    batches = 1000\n",
    "    f0_arr = np.ndarray(max(0,min(y.size,batches*batch_size-W)//hop))\n",
    "    f0_arr[0] = 0.0\n",
    "\n",
    "    for b in range(batches):\n",
    "        if b%10 == 0:\n",
    "            print(\"Batch \" + str(b) + \" from t=\" + str(start) + \" to \" + str(end))\n",
    "\n",
    "        # Compute autocorrelation and difference functions for a range of t \n",
    "        acf1=get_acf_in_range(y, W, start, end)\n",
    "        relative_times = np.arange(0,last_t-start,1)\n",
    "        d = diff_function(acf1, relative_times)   \n",
    "\n",
    "        # Compute normalized difference function and find minima of parabolas that fit local minima\n",
    "        normd = normalize_diff(d)\n",
    "        qnormd = quadratic_mins(normd) # all local mins at each time t\n",
    "        qnormd[~local_mins(normd)] = 1            \n",
    "\n",
    "        # Get estimated period T_theta and d'(T_theta) (using the parabola), for each time theta\n",
    "        debug_times = None\n",
    "        if b == -1:\n",
    "            debug_times = np.arange(138240-start, 139680-start, 480)\n",
    "        T_thetas = get_all_periods(qnormd, debug_times) \n",
    "        T_theta_qnormds = qnormd[relative_times, T_thetas]\n",
    "    \n",
    "        # create a row of d'(T_theta)'s for each neighborhood of each time of interest\n",
    "        # - the times of interest are start+hop, start+2*hop, ..., last_t-hop\n",
    "        # - the neighborhoods of interest span times:\n",
    "        #     start+hop-t_window//2   ... start+hop+t_window//2\n",
    "        #     start+2*hop-t_window//2 ... start+2*hop+t_window//2\n",
    "        #     ...\n",
    "        #     last_t-hop-t_window//2  ... last_t-hop+t_window//2\n",
    "        relative_f0_times = np.arange(hop,last_t-start,hop)\n",
    "        start_t = hop-t_window//2\n",
    "        end_t = (last_t-start)-hop+t_window//2+1\n",
    "        T_theta_qnormd_windows = \\\n",
    "            rolling_window_1d(T_theta_qnormds[start_t:end_t], t_window+1, hop)\n",
    "\n",
    "        ### for each time t of interest:\n",
    "        ## - get the argmin, \\theta_0, of the nearby d'(T_theta)'s\n",
    "        theta_0s = np.argmin(T_theta_qnormd_windows,axis=1) + relative_f0_times - t_window//2\n",
    "\n",
    "        ## - get the period \\T_theta of qnormd at each time in theta_0s - there's one for each time of interest\n",
    "        T_theta_0s = T_thetas[theta_0s]\n",
    "\n",
    "        ## - find min of d_t near \\T_theta_0:\n",
    "        periods = get_desired_periods(d[relative_f0_times,:], T_theta_0s)\n",
    "\n",
    "        ### debugging ###\n",
    "        if b == -1:\n",
    "            for t in np.arange(138240-start, 139680-start, 480):\n",
    "                idx = (t-hop)//hop\n",
    "                print(t+start, theta_0s[idx], T_theta_0s[idx])\n",
    "                plt.plot(normd[t,:],'.')\n",
    "                plt.plot(qnormd[t,:],'.')\n",
    "                plt.plot(normd[theta_0s[idx],:],'.')\n",
    "                plt.plot(qnormd[theta_0s[idx],:],'.')\n",
    "                plt.ylim(0,.005)\n",
    "                plt.show()            \n",
    "\n",
    "        ## - add to f0\n",
    "        #  need y[t] for start+hop <= t <= last_t - hop + W -1\n",
    "        y_windows = rolling_window_1d(y[start+hop:end-hop], W, hop)\n",
    "        quiet_times = np.max(y_windows, axis=1)<min_singing_volume()\n",
    "        f0_arr[start//hop+1:last_t//hop] = np.where(np.logical_or(quiet_times,periods < sr/max_f0()),0,sr/periods)\n",
    "\n",
    "        if end > y.size-2*W - hop:\n",
    "            break\n",
    "        start = last_t-hop\n",
    "        end = min(y.size-2*W, end + batch_size)\n",
    "        end = end - end%hop\n",
    "        last_t = end-W\n",
    "    return f0_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy tricks worth recording\n",
    "\n",
    "#### Trick 1: Rolling window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1], [2],[3],[4], [5], [6], [7], [8]])\n",
    "y = np.array([1,2,3,4,5,6,7,8])\n",
    "print(x.strides,y.strides)\n",
    "print(x)\n",
    "def rolling_window_1d(a, window, hop):\n",
    "    shape = ((a.shape[0] - window + hop)//hop, window)\n",
    "    strides = (a.strides[0]*hop, a.strides[0])\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)\n",
    "print(rolling_window_1d(x,5,2))\n",
    "print(rolling_window_1d(y,4,4))\n",
    "print(np.mean(rolling_window_1d(y,5,2),axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trick 2. Logical-AND of a column array and a row array is a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12],[13,14,15,16],[17,18,19,20]])\n",
    "thr = np.array([[2],[0],[1],[3],[1]])\n",
    "cond = np.logical_and((np.arange(4)>=thr-1),(np.arange(4)<=thr+1))\n",
    "np.where(cond,x,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trick 3. Add a 2d array to a 1d array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12],[13,14,15,16],[17,18,19,20]])\n",
    "x+np.arange(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trick 4. meshgrid\n",
    "\n",
    "- given two 1d arrays of points, creates two 2d arrays: the x coords and y coords of the cross product of the 1d arrays\n",
    "- needs to be told, using indexing='ij', to get the order of x and y right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "print(np.random.random((2, 4)))\n",
    "\n",
    "# Set up grid and test data\n",
    "nx, ny = 3, 5\n",
    "x = range(nx)\n",
    "y = range(ny)\n",
    "\n",
    "data = np.random.random((nx, ny))\n",
    "\n",
    "hf = plt.figure()\n",
    "ha = hf.add_subplot(111, projection='3d')\n",
    "\n",
    "X, Y = np.meshgrid(x, y, indexing='ij')  # `plot_surface` expects `x` and `y` data to be 2D\n",
    "print(X)\n",
    "print(Y)\n",
    "print(X.shape, Y.shape, data.shape)\n",
    "ha.plot_surface(X, Y, data)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trick 5. Use one array as the indices into another array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([150, 200, 250, 175])\n",
    "arg = [0,1,0,3]\n",
    "x[arg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = y = z = np.arange(0.0,5.0,1.0)\n",
    "np.savetxt('test.out', np.column_stack((x,y,z)))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
