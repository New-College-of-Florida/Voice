{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_features = PolynomialFeatures(degree=3, include_bias=False)\n",
    "scaler = scaler = pickle.load(open( \"standard_scaler.out\", \"rb\" ))\n",
    "rfr = pickle.load(open(\"optimizedRandomForestRegressor.out\", \"rb\" ))\n",
    "crfr = rfr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate(adir):\n",
    "    conv={}\n",
    "    conv[0] = lambda s: float(s.strip() or 0)\n",
    "    x,y = np.loadtxt(adir, unpack=True, usecols=(0,1), converters=conv)\n",
    "    return (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_pitch (estimates):\n",
    "    print(type(estimates))\n",
    "    a = np.array([estimates])\n",
    "    ap = poly_features.fit_transform(a)\n",
    "    print(ap)\n",
    "    aps = scaler.transform(ap)\n",
    "    return crfr.predict(aps)\n",
    "\n",
    "\n",
    "def find_optimal_pitch (current_collections, collection, part):\n",
    "    pitch_estimates = []\n",
    "    time = current_collections[collection]['boersma'][part][0]\n",
    "    \n",
    "    for algo in algorithms:\n",
    "        if part in current_collections[collection][algo]:\n",
    "            pitch_estimates.append(current_collections[collection][algo][part][1])    \n",
    "            \n",
    "            if len(current_collections[collection][algo][part][0]) < len(time):\n",
    "                time = current_collections[collection][algo][part][0]\n",
    "    \n",
    "    best_estimate = np.empty(len(time))\n",
    "    \n",
    "    for i in range(len(time)):\n",
    "        current_pitches = []\n",
    "        for pitches in pitch_estimates:\n",
    "            current_pitches.append(pitches[i])\n",
    "        best_estimate[i] = estimate_pitch(current_pitches)\n",
    "        std[i] = standard_deviation(current_pitches)\n",
    "        med[i] = median(current_pitches)\n",
    "        \n",
    "    return (time, best_estimate, std, med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "collections = {\n",
    "    \"GVM009\": {},\n",
    "    \"GVM017\": {},\n",
    "    \"GVM019\": {},\n",
    "    \"GVM031\": {},\n",
    "    \"GVM097\": {}\n",
    "}\n",
    "\n",
    "algorithms = ['boersma', 'crepe', 'hermes', 'maddox', 'noll', 'praat']\n",
    "data_dir = '/Akamai/voice/data/pitches-vuv/'\n",
    "\n",
    "for collection in collections:\n",
    "    for algo in algorithms:\n",
    "        collections[collection][algo] = {}\n",
    "\n",
    "for algorithm in os.listdir(data_dir):\n",
    "    if not algorithm in algorithms:\n",
    "        continue\n",
    "    for collection in os.listdir(f\"{data_dir}{algorithm}\"):\n",
    "        if collection != 'Scherbaum Mshavanadze':\n",
    "            continue\n",
    "        for song in os.listdir(f\"{data_dir}{algorithm}/{collection}\"):\n",
    "            for part in os.listdir(f\"{data_dir}{algorithm}/{collection}/{song}\"):\n",
    "                print(part)\n",
    "                if part[:6] in collections:\n",
    "                    if 'AHDS' in part:\n",
    "                        x, y = separate(f\"{data_dir}{algorithm}/{collection}/{song}/{part}\")\n",
    "                        collections[part[:6]][algorithm][part[part.index('AHDS'):part.index('AHDS')+6]] = (x, y)\n",
    "                    elif 'ALRX' in part:\n",
    "                        x, y = separate(f\"{data_dir}{algorithm}/{collection}/{song}/{part}\")\n",
    "                        collections[part[:6]][algorithm][part[part.index('ALRX'):part.index('ALRX')+6]] = (x, y)\n",
    "                    elif 'AOLS' in part:\n",
    "                        x, y = separate(f\"{data_dir}{algorithm}/{collection}/{song}/{part}\")\n",
    "                        collections[part[:6]][algorithm][part[part.index('AOLS'):part.index('AOLS')+6]] = (x, y)\n",
    "                    elif 'VSOA' in part:\n",
    "                        x, y = separate(f\"{data_dir}{algorithm}/{collection}/{song}/{part}\")\n",
    "                        collections[part[:6]][algorithm][part[part.index('VSOA'):part.index('VSOA')+6]] = (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = ['AHDS1M', 'AHDS2M', 'AHDS3M', 'ALRX1M', 'ALRX2M', 'ALRX3M', 'VSOAX4', 'AOLS5S']\n",
    "\n",
    "res_dir = '/Akamai/voice/data/ground-estimate-rfr/Scherbaum Mshavanadze/'\n",
    "\n",
    "for collection in collections:\n",
    "    for part in parts:\n",
    "        t, estimate, cstd, cmed = find_optimal_pitch(collections, collection, part)\n",
    "        if not os.path.isdir(res_dir + collection):\n",
    "            os.mkdir(res_dir + collection)\n",
    "            \n",
    "        if not os.path.isdir(std_dir + collection):\n",
    "            os.mkdir(std_dir + collection)\n",
    "        \n",
    "        if not os.path.isdir(med_dir + collection):\n",
    "            os.mkdir(med_dir + collection)\n",
    "        \n",
    "        # ground estimate\n",
    "        np.savetxt(res_dir + collection + '/' + part + '.txt', np.c_[t, estimate], delimiter=' ', fmt='%f')\n",
    "        \n",
    "        print(f\"{part}:{collection} done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "a = np.array([[1, 2, 3, 4]])\n",
    "ap = poly_features.fit_transform(a)\n",
    "aps = scaler.transform(ap)\n",
    "\n",
    "current_rfr = rfr.best_estimator_\n",
    "print(current_rfr.predict(aps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[0, 0, 0, 0, 0], [0, 0, 0, 0, 0]])\n",
    "ap = poly_features.fit_transform(a)\n",
    "aps = scaler.transform(ap)\n",
    "crfr.predict(aps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
