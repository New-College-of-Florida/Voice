{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_pitch (estimates):\n",
    "    estimates = sorted(estimates)\n",
    "    X = np.array(estimates).reshape(-1, 1)\n",
    "    clustering = AgglomerativeClustering(n_clusters=None, \n",
    "                                         affinity='euclidean', \n",
    "                                         linkage='average', \n",
    "                                         distance_threshold=5).fit(X)\n",
    "    clusters = []\n",
    "    for i in range(np.max(clustering.labels_)+1):\n",
    "        ccount = 0\n",
    "        csum = 0\n",
    "        for j, e in enumerate(clustering.labels_):\n",
    "            if e == i:\n",
    "                ccount += 1\n",
    "                csum += estimates[j] \n",
    "        clusters.append((ccount, csum / ccount))\n",
    "    clusters.sort(reverse=True)\n",
    "    return clusters[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_pitch (current_collections, collection, part):\n",
    "    pitch_estimates = []\n",
    "    time = current_collections[collection]['boersma'][part][0]\n",
    "    \n",
    "    for algo in algorithms:\n",
    "        if part in current_collections[collection][algo]:\n",
    "            pitch_estimates.append(current_collections[collection][algo][part][1])    \n",
    "            \n",
    "            if len(current_collections[collection][algo][part][0]) < len(time):\n",
    "                time = current_collections[collection][algo][part][0]\n",
    "    \n",
    "    best_estimate = np.empty(len(time))\n",
    "    for i in range(len(time)):\n",
    "        current_pitches = []\n",
    "        for pitches in pitch_estimates:\n",
    "            current_pitches.append(pitches[i])\n",
    "        best_estimate[i] = estimate_pitch(current_pitches)\n",
    "        \n",
    "    return (time, best_estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scherbaum Mshavanadze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "collections = {\n",
    "    \"GVM009\": {},\n",
    "    \"GVM017\": {},\n",
    "    \"GVM019\": {},\n",
    "    \"GVM031\": {},\n",
    "    \"GVM097\": {}\n",
    "}\n",
    "\n",
    "algorithms = ['boersma', 'crepe', 'hermes', 'maddox', 'noll', 'praat']\n",
    "data_dir = '/Akamai/voice/data/pitches-vuv/'\n",
    "\n",
    "for collection in collections:\n",
    "    for algo in algorithms:\n",
    "        collections[collection][algo] = {}\n",
    "        \n",
    "def separate(adir):\n",
    "    conv={}\n",
    "    conv[0] = lambda s: float(s.strip() or 0)\n",
    "    x,y = np.loadtxt(adir, unpack=True, usecols=(0,1), converters=conv)\n",
    "    return (x,y)\n",
    "\n",
    "for algorithm in os.listdir(data_dir):\n",
    "    if not algorithm in algorithms:\n",
    "        continue\n",
    "    for collection in os.listdir(f\"{data_dir}{algorithm}\"):\n",
    "        if collection != 'Scherbaum Mshavanadze':\n",
    "            continue\n",
    "        for song in os.listdir(f\"{data_dir}{algorithm}/{collection}\"):\n",
    "            for part in os.listdir(f\"{data_dir}{algorithm}/{collection}/{song}\"):\n",
    "                print(part)\n",
    "                if part[:6] in collections:\n",
    "                    if 'AHDS' in part:\n",
    "                        x, y = separate(f\"{data_dir}{algorithm}/{collection}/{song}/{part}\")\n",
    "                        collections[part[:6]][algorithm][part[part.index('AHDS'):part.index('AHDS')+6]] = (x, y)\n",
    "                    elif 'ALRX' in part:\n",
    "                        x, y = separate(f\"{data_dir}{algorithm}/{collection}/{song}/{part}\")\n",
    "                        collections[part[:6]][algorithm][part[part.index('ALRX'):part.index('ALRX')+6]] = (x, y)\n",
    "                    elif 'AOLS' in part:\n",
    "                        x, y = separate(f\"{data_dir}{algorithm}/{collection}/{song}/{part}\")\n",
    "                        collections[part[:6]][algorithm][part[part.index('AOLS'):part.index('AOLS')+6]] = (x, y)\n",
    "                    elif 'VSOA' in part:\n",
    "                        x, y = separate(f\"{data_dir}{algorithm}/{collection}/{song}/{part}\")\n",
    "                        collections[part[:6]][algorithm][part[part.index('VSOA'):part.index('VSOA')+6]] = (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parts = ['AHDS1M', 'AHDS2M', 'AHDS3M', 'ALRX1M', 'ALRX2M', 'ALRX3M', 'VSOAX4', 'AOLS5S']\n",
    "\n",
    "res_dir = '/Akamai/voice/data/ground-estimate/Scherbaum Mshavanadze/'\n",
    "for collection in collections:\n",
    "    for part in parts:\n",
    "        t, estimate = find_optimal_pitch(collections, collection, part)\n",
    "        if not os.path.isdir(res_dir + collection):\n",
    "            os.mkdir(res_dir + collection)\n",
    "        np.savetxt(res_dir + collection + '/' + part + '.txt', np.c_[t, estimate], delimiter=' ', fmt='%f')\n",
    "        print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teach Yourself Megrelian Songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "collections2 = {\n",
    "    \"Ak'a Si Rekisho\": {},\n",
    "    'Gepshvat Ghvini': {},\n",
    "    'Io _ Chkin Kiana': {},\n",
    "    'Mesishi Vardi': {},\n",
    "    'Meureme': {},\n",
    "    'Mi Re Sotsodali_': {},\n",
    "    \"Mole Chit'i Gilakhe\": {},\n",
    "    'O Da': {},\n",
    "    'Vojanudi Chkim Jargvals': {}\n",
    "}\n",
    "\n",
    "algorithms = ['boersma', 'crepe', 'hermes', 'maddox', 'noll']\n",
    "data_dir = '/Akamai/voice/data/pitches-vuv/'\n",
    "\n",
    "for collection in collections2:\n",
    "    for algo in algorithms:\n",
    "        collections2[collection][algo] = {}\n",
    "        \n",
    "def separate(adir, algo):\n",
    "    conv={}\n",
    "    conv[0] = lambda s: float(s.strip() or 0)\n",
    "    x,y = np.loadtxt(adir, unpack=True, usecols=(0,1), converters=conv)\n",
    "    return (x,y)\n",
    "\n",
    "def root_name (name):\n",
    "    s = None; e = None\n",
    "    for i in range(len(name)-2, 0, -1):\n",
    "        if name[i] == '.': e = i;\n",
    "        elif name[i:i+2] == '_A': \n",
    "            s = i\n",
    "            break\n",
    "    \n",
    "    if s == None: return name[:e];\n",
    "    else: return name[:s];\n",
    "\n",
    "for algorithm in os.listdir(data_dir):\n",
    "    if not algorithm in algorithms:\n",
    "        continue\n",
    "    for collection in os.listdir(f\"{data_dir}{algorithm}\"):\n",
    "        if collection != 'Teach Yourself Megrelian Songs':\n",
    "            continue\n",
    "        for song in os.listdir(f\"{data_dir}{algorithm}/{collection}\"):\n",
    "            for part in os.listdir(f\"{data_dir}{algorithm}/{collection}/{song}\"):\n",
    "                if root_name(part) in collections2:\n",
    "                    if 'AHDS' in part:\n",
    "                        x, y = separate(f\"{data_dir}{algorithm}/{collection}/{song}/{part}\", algorithm)\n",
    "                        collections2[root_name(part)][algorithm][part[part.index('AHDS'):part.index('AHDS')+6]] = (x, y)\n",
    "                    else:\n",
    "                        x, y = separate(f\"{data_dir}{algorithm}/{collection}/{song}/{part}\", algorithm)\n",
    "                        collections2[root_name(part)][algorithm]['VSOAX4'] = (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = ['AHDS1M', 'AHDS2M', 'AHDS3M', 'VSOAX4']\n",
    "\n",
    "res_dir = '/Akamai/voice/data/ground-estimate/Teach Yourself Megrelian Songs/'\n",
    "for collection in collections2:\n",
    "    for part in parts:\n",
    "        t, estimate = find_optimal_pitch(collections2, collection, part)\n",
    "        if not os.path.isdir(res_dir + collection):\n",
    "            os.mkdir(res_dir + collection)\n",
    "            \n",
    "        np.savetxt(res_dir + collection + '/' + part + '.txt', np.c_[t, estimate], delimiter=' ', fmt='%f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teach Yourself Gurian Songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "collections3 = {\n",
    "    \"Adila-Alipasha\": {},\n",
    "    \"Indi-Mindi\": {},\n",
    "    'Mival Guriashi (1)': {} ,\n",
    "    'Pikris Simghera': {},\n",
    "    \"Alaverdi\": {},\n",
    "    \"K'alos Khelkhvavi\": {},\n",
    "    'Mival Guriashi (2)' : {}, \n",
    "    \"Sabodisho\": {},\n",
    "    \"Khasanbegura\": {},     \n",
    "    \"Mok'le Mravalzhamieri\": {},\n",
    "    'Sadats Vshobilvar': {},\n",
    "    \"Beri Ak'vans Epareba\": {}, \n",
    "    \"Lat'aris Simghera\": {},    \n",
    "    \"Mts'vanesa Da Ukudosa\": {}, \n",
    "    \"Shermanduli\": {},\n",
    "    \"Brevalo\": {},             \n",
    "    \"Manana\": {},         \n",
    "    'Nanina (1)': {},      \n",
    "    \"Shvidk'atsa\": {},\n",
    "    \"Chven-Mshvidoba\": {},    \n",
    "    \"Maq'ruli\": {},               \n",
    "    'Nanina (2)': {},          \n",
    "    'Supris Khelkhvavi': {},\n",
    "    'Didi Khnidan': {},     \n",
    "    \"Masp'indzelsa Mkhiarulsa\": {}, \n",
    "    \"Orira\": {},                \n",
    "    \"Ts'amok'ruli\": {},\n",
    "    \"Gakhsovs, T'urpa\": {},\n",
    "    \"Me-Rustveli\": {},        \n",
    "    \"P'at'ara Saq'varelo\": {}\n",
    "}\n",
    "\n",
    "algorithms = ['boersma', 'crepe', 'hermes', 'maddox', 'noll']\n",
    "data_dir = '/Akamai/voice/data/pitches-vuv/'\n",
    "\n",
    "for collection in collections3:\n",
    "    for algo in algorithms:\n",
    "        collections3[collection][algo] = {}\n",
    "        \n",
    "def separate(adir, algo):\n",
    "    conv={}\n",
    "    conv[0] = lambda s: float(s.strip() or 0)\n",
    "    x,y = np.loadtxt(adir, unpack=True, usecols=(0,1), converters=conv)\n",
    "    return (x,y)\n",
    "\n",
    "def root_name (name):\n",
    "    s = None; e = None\n",
    "    for i in range(len(name)-2, 0, -1):\n",
    "        if name[i] == '.': e = i;\n",
    "        elif name[i:i+2] == '_A': \n",
    "            s = i\n",
    "            break\n",
    "    \n",
    "    if s == None: return name[:e];\n",
    "    else: return name[:s];\n",
    "\n",
    "for algorithm in os.listdir(data_dir):\n",
    "    if not algorithm in algorithms:\n",
    "        continue\n",
    "    for collection in os.listdir(f\"{data_dir}{algorithm}\"):\n",
    "        if collection != 'Teach Yourself Gurian Songs':\n",
    "            continue\n",
    "        for song in os.listdir(f\"{data_dir}{algorithm}/{collection}\"):\n",
    "            for part in os.listdir(f\"{data_dir}{algorithm}/{collection}/{song}\"):\n",
    "                print(root_name(part))\n",
    "                if root_name(part) in collections3:\n",
    "                    if 'AHDS' in part:\n",
    "                        x, y = separate(f\"{data_dir}{algorithm}/{collection}/{song}/{part}\", algorithm)\n",
    "                        collections3[root_name(part)][algorithm][part[part.index('AHDS'):part.index('AHDS')+6]] = (x, y)\n",
    "                    else:\n",
    "                        x, y = separate(f\"{data_dir}{algorithm}/{collection}/{song}/{part}\", algorithm)\n",
    "                        collections3[root_name(part)][algorithm]['VSOAX4'] = (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parts = ['AHDS1M', 'AHDS2M', 'AHDS3M', 'VSOAX4']\n",
    "\n",
    "res_dir = '/Akamai/voice/data/ground-estimate/Teach Yourself Gurian Songs/'\n",
    "for collection in collections3:\n",
    "    for part in parts:\n",
    "        t, estimate = find_optimal_pitch(collections3, collection, part)\n",
    "        if not os.path.isdir(res_dir + collection):\n",
    "            os.mkdir(res_dir + collection)\n",
    "            \n",
    "        np.savetxt(res_dir + collection + '/' + part + '.txt', np.c_[t, estimate], delimiter=' ', fmt='%f')\n",
    "        print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing and Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Akamai/voice/data/ground-estimate/Scherbaum Mshavanadze/'\n",
    "data_dir += os.listdir(data_dir)[0] + '/'\n",
    "data_dir += os.listdir(data_dir)[0]\n",
    "\n",
    "x, y = separate(data_dir)\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(x, y, '.', markersize=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate_pitch([201.9599, 201.3181, 201.1465, 200.005, 67.73271])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster import hierarchy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitches = [201.9599, 201.3181, 201.1465, 200.005, 67.73271, 65.234, 90.23084]\n",
    "X = np.array(pitches).reshape(-1, 1)\n",
    "Z = hierarchy.linkage(X, 'average')\n",
    "plt.figure()\n",
    "dn = hierarchy.dendrogram(Z)\n",
    "plt.ylim(0, 10)\n",
    "\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recurse_find (start_index, N, Z):\n",
    "    ans = []\n",
    "    \n",
    "    x = int(Z[start_index][0])\n",
    "    y = int(Z[start_index][1])\n",
    "    w = Z[start_index][2]\n",
    "    \n",
    "    if x < N: ans.append(x)\n",
    "    if y < N: ans.append(y)\n",
    "        \n",
    "    if x >= N: ans += recurse_find(x - N, N, Z)\n",
    "    if y >= N:ans += recurse_find(y - N, N, Z)\n",
    "    \n",
    "    return ans\n",
    "\n",
    "def traverse_dendogram (N, Z):   \n",
    "    clusters = set([0, 1, 2, 3, 4])\n",
    "    \n",
    "    for i in range(Z.shape[0]):\n",
    "        x = int(Z[i][0])\n",
    "        y = int(Z[i][1])\n",
    "        w = Z[i][2]\n",
    "        \n",
    "    return cluster_values\n",
    "    \n",
    "\n",
    "# a = traverse_dendogram(hierarchy.linkage(X, 'average'))\n",
    "recurse_find(2, len(pitches), Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_labels (estimates):\n",
    "    current_threshold = 5\n",
    "    X = np.array(estimates).reshape(-1, 1)\n",
    "    current_clustering = None\n",
    "    \n",
    "    while True:\n",
    "        aglo_clust = AgglomerativeClustering(n_clusters=None, \n",
    "                                         affinity='euclidean', \n",
    "                                         linkage='average', \n",
    "                                         distance_threshold=current_threshold)\n",
    "        current_clustering = aglo_clust.fit(X)\n",
    "        stats = Counter(current_clustering.labels_).most_common()\n",
    "        \n",
    "        if len(stats) >= 2 and stats[0][1] == stats[1][1]:\n",
    "            current_threshold += 1\n",
    "        else: break\n",
    "            \n",
    "    return current_clustering.labels_\n",
    "            \n",
    "\n",
    "def estimate_pitch (estimates):\n",
    "    estimates = sorted(estimates)\n",
    "    clustering = calculate_labels(estimates)\n",
    "    print(estimates)\n",
    "    print(clustering)\n",
    "    clusters = []\n",
    "    for i in range(np.max(clustering)+1):\n",
    "        ccount = 0\n",
    "        csum = 0\n",
    "        for j, e in enumerate(clustering):\n",
    "            if e == i:\n",
    "                ccount += 1\n",
    "                csum += estimates[j] \n",
    "        clusters.append((ccount, csum / ccount))\n",
    "    clusters.sort(reverse=True)\n",
    "    return clusters[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitches = [201.9599, 201.3181, 201.1465, 200.005, 67.73271, 65.234, 68.322, 69.212]\n",
    "X = np.array(pitches).reshape(-1, 1)\n",
    "Z = hierarchy.linkage(X, 'average')\n",
    "print(estimate_pitch(pitches))\n",
    "print(sorted(pitches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter([0, 0, 2, 2, 3, 3, 3, 3, 1, 1, 1, 1,]).most_common()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
