{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Random Forest Regressor to predict ground-estimate\n",
    "\n",
    "The code involves using sklearn's random forest regressor to predict ground-estimate based on the 5 algorithms' output, which are treated as features. The code used the larynx microphone data generated form Scherbaum Mshavanadze using CREPE to train the model. RandomizedSearchCV was used to choose the best parameters for the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate(adir):\n",
    "    conv={}\n",
    "    conv[0] = lambda s: float(s.strip() or 0)\n",
    "    x,y = np.loadtxt(adir, unpack=True, usecols=(0,1), converters=conv)\n",
    "    return (x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting and Organizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Akamai/voice/data/pitches-vuv/'\n",
    "collection = 'Scherbaum Mshavanadze'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "algos = ['crepe', 'hermes', 'maddox', 'noll', 'yin', 'boersma']\n",
    "data = {algo: {} for algo in algos}\n",
    "\n",
    "for algo in os.listdir(data_dir):\n",
    "    if algo not in algos: continue\n",
    "    for song in os.listdir(f\"{data_dir}{algo}/{collection}\"):\n",
    "        for part in os.listdir(f\"{data_dir}{algo}/{collection}/{song}\"):\n",
    "            if os.path.isdir(f\"{data_dir}{algo}/{collection}/{song}/{part}\"): continue\n",
    "            coll = song[:6]\n",
    "            label = part[-10:-4]\n",
    "            x, y = separate(f\"{data_dir}{algo}/{collection}/{song}/{part}\")            \n",
    "            if not coll in data[algo]:\n",
    "                data[algo][coll] = {}\n",
    "            data[algo][coll][label] = (x, y)\n",
    "    print(algo, \"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "for algo in data.keys():\n",
    "    if algo != 'crepe':\n",
    "        X.append(data[algo])\n",
    "y = data['crepe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = np.array([])\n",
    "Y = np.array([])\n",
    "\n",
    "collections = ['AHDS1M', 'AHDS2M', 'AHDS3M', 'ALRX1M', 'ALRX2M', 'ALRX3M']\n",
    "songs = ['GVM009', 'GVM017', 'GVM019', 'GVM031', 'GVM097']\n",
    "\n",
    "for song in songs:\n",
    "    for collection in collections:\n",
    "        cx = []\n",
    "        cy = []\n",
    "        for algo in algos:\n",
    "            if algo == 'crepe': continue\n",
    "            cx.append(data[algo][song][collection][1])\n",
    "            \n",
    "        if '1' in collection: cy.append(data['crepe'][song]['ALRX1M'][1])\n",
    "        elif '2' in collection: cy.append(data['crepe'][song]['ALRX2M'][1])\n",
    "        else: cy.append(data['crepe'][song]['ALRX3M'][1])\n",
    "        \n",
    "        if len(X) == 0:\n",
    "            X = np.transpose(np.array(cx))\n",
    "            Y = np.transpose(np.array(cy))\n",
    "        else:\n",
    "            X = np.vstack((X, np.transpose(np.array(cx))))\n",
    "            Y = np.vstack((Y, np.transpose(np.array(cy))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_features = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X_poly_train = poly_features.fit_transform(X_train)\n",
    "X_poly_test = poly_features.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_poly_train)\n",
    "X_train_scaled = scaler.transform(X_poly_train)\n",
    "X_test_scaled = scaler.transform(X_poly_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Used Polynomial Regression to train the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train_scaled, y_train)\n",
    "mean_squared_error(y_test, lin_reg.predict(X_test_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Also attempted trained RandomForestRegressor to train the data.\n",
    "\n",
    "The results were better with Random Forest Regressor. This block takes a while to run. The algorithm's object is already saved as a pickle under the name of \"optimizedRandomForestRegressor.out\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "random_grid = {'bootstrap': [True, False],\n",
    "               'max_depth': [12, 13, 14, 15, 17, 18],\n",
    "               'max_features': ['auto', 'sqrt', 'log2'],\n",
    "               'min_samples_leaf': [1, 2, 4],\n",
    "               'min_samples_split': [2, 5, 10],\n",
    "               'n_estimators': [130, 180, 230]}\n",
    "\n",
    "rnd_search = RandomizedSearchCV(RandomForestRegressor(), random_grid, scoring=\"neg_mean_squared_error\", random_state=42, n_iter=10, cv=9, verbose=2)\n",
    "rnd_search.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, rnd_search.predict(X_test_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few examples of how well the RandomForestRegressor performs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(10):\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.plot(sorted(y_test[100 * i:100 * i + 100]), '.')\n",
    "    plt.plot(sorted(rnd_search.predict(X_test_scaled)[100 * i:100 * i + 100]), '.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
