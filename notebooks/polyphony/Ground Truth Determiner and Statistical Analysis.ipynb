{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook populates the ground estimates and MAD statistics.\n",
    "\n",
    "It takes Crepe estimates from `/Akamai/voice/data/pitches-postprocessed/`\n",
    "and estimates for Boersma, Hermes, Noll, Yin froom `/Akamai/voice/data/pitches-vuv-crepe-assisted/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "from scipy.stats import median_abs_deviation\n",
    "from statistics import median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_correction_dir = '/Akamai/voice/data/pitch-overrides/crepe/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_dir(parent_dir, curr_dir):\n",
    "    for each in os.listdir(parent_dir):\n",
    "        if curr_dir in each:\n",
    "            return each\n",
    "    return curr_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_correction_box (corrections, time):\n",
    "    for correction in corrections:\n",
    "        if correction[0] <= time <= correction[2]:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def check_correction_pitch (corrections, time, pitch):\n",
    "    for correction in corrections:\n",
    "        if correction[0] <= time <= correction[2]:\n",
    "            return (correction[1] <= pitch <= correction[3])\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_corrections(name):\n",
    "    corrections = [] # (t1, t2, p1, p2)\n",
    "    try: correction_file = open(f'{name}')\n",
    "    except: \n",
    "        print('no correction file for', name)\n",
    "        return []\n",
    "    for line in correction_file:\n",
    "        current_corrections = list(map(float, line.split(' ')))\n",
    "        corrections.append(current_corrections)\n",
    "    return corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mean (estimates):\n",
    "    estimates = estimates.T\n",
    "    mean_output = np.empty(len(estimates))\n",
    "    for i in range(len(estimates)):        \n",
    "        mean_output[i] = np.mean(estimates[i][estimates[i] >= 0])\n",
    "    return mean_output\n",
    "\n",
    "def find_median (estimates):\n",
    "    estimates = estimates.T\n",
    "    median_output = np.empty(len(estimates))\n",
    "    for i in range(len(estimates)):\n",
    "        median_output[i] = np.median(estimates[i][estimates[i] >= 0])\n",
    "    return median_output\n",
    "\n",
    "def find_std (estimates):\n",
    "    estimates = estimates.T\n",
    "    std_output = np.empty(len(estimates))\n",
    "    for i in range(len(estimates)):\n",
    "        std_output[i] = np.std(estimates[i][estimates[i] >= 0])\n",
    "    return std_output\n",
    "\n",
    "def find_mad (estimates):\n",
    "    estimates = estimates.T\n",
    "    std_output = np.empty(len(estimates))\n",
    "    for i in range(len(estimates)):\n",
    "        # some 0 estimates are not precisely 0\n",
    "        std_output[i] = median_abs_deviation(np.where(estimates[i] >= 1, estimates[i], 0*estimates[i]))\n",
    "    return std_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate(adir):\n",
    "    conv={}\n",
    "    conv[0] = lambda s: float(s.strip() or 0)\n",
    "    x,y = np.loadtxt(adir, unpack=True, usecols=(0,1), converters=conv)\n",
    "    return (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new model\n",
    "def calculate_labels (estimates):\n",
    "    current_threshold = 5\n",
    "    X = np.array(estimates).reshape(-1, 1)\n",
    "    current_clustering = None\n",
    "    \n",
    "    while True:\n",
    "        aglo_clust = AgglomerativeClustering(n_clusters=None, \n",
    "                                         affinity='euclidean', \n",
    "                                         linkage='average', \n",
    "                                         distance_threshold=current_threshold)\n",
    "        current_clustering = aglo_clust.fit(X)\n",
    "        stats = Counter(current_clustering.labels_).most_common()\n",
    "        \n",
    "        if len(stats) >= 2 and stats[0][1] == stats[1][1]:\n",
    "            current_threshold += 1\n",
    "        else: break\n",
    "            \n",
    "    return current_clustering.labels_\n",
    "            \n",
    "\n",
    "def estimate_pitch (estimates):\n",
    "    return median(estimates)\n",
    "\n",
    "#     if min(estimates) < 0:\n",
    "#         print(\"estimates:\", list(map(lambda x: round(x, 2), estimates)))\n",
    "\n",
    "#     if len(estimates) == 1:\n",
    "#         print(estimates)\n",
    "#         return estimates[0]\n",
    "    \n",
    "#     estimates = sorted(estimates)\n",
    "#     clustering = calculate_labels(estimates)\n",
    "#     clusters = []\n",
    "#     for i in range(np.max(clustering)+1):\n",
    "#         ccount = 0\n",
    "#         csum = 0\n",
    "#         for j, e in enumerate(clustering):\n",
    "#             if e == i:\n",
    "#                 ccount += 1\n",
    "#                 csum += estimates[j] \n",
    "#         clusters.append((ccount, csum / ccount))\n",
    "#     clusters.sort(reverse=True)\n",
    "    \n",
    "#     if clusters[0][1] > 900 or min(estimates) < 0:\n",
    "#         print(\"estimates:\", list(map(lambda x: round(x, 2), estimates)), \"Estimate:\", round(clusters[0][1], 2))\n",
    "#     return clusters[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_pitch (current_collections, collection, part):\n",
    "    pitch_estimates = []\n",
    "    time = len(current_collections[collection]['boersma'][part][0])\n",
    "    \n",
    "    full_collection = match_dir(correction_dir, collection)\n",
    "    full_part = match_dir(os.path.join(correction_dir, full_collection), part)\n",
    "    current_corrections = load_corrections(os.path.join(correction_dir, \n",
    "                                                            full_collection, \n",
    "                                                            full_part))\n",
    "    \n",
    "    for algo in algorithms:\n",
    "        if part in current_collections[collection][algo]:\n",
    "            if algo == 'crepe':\n",
    "                crepe_pitches = current_collections[collection][algo][part][1]\n",
    "                pitch_estimates.append(crepe_pitches)\n",
    "                if len(crepe_pitches) < time:\n",
    "                    time = len(crepe_pitches)\n",
    "            else:\n",
    "                pitch_estimates.append(current_collections[collection][algo][part][1])\n",
    "                if len(current_collections[collection][algo][part][0]) < time:\n",
    "                    time = len(current_collections[collection][algo][part][0])\n",
    "    \n",
    "    best_estimate = np.zeros(time)\n",
    "\n",
    "    for i in range(time):\n",
    "        current_pitches = []\n",
    "        for j, pitches in enumerate(pitch_estimates):\n",
    "            include_pitch = True\n",
    "            if (algorithms[j] == 'boersma' or algorithms[j] == 'yin' or algorithms[j] == 'hermes') and pitches[i] == 0:\n",
    "                include_pitch = False\n",
    "            if include_pitch:\n",
    "                current_pitches.append(pitches[i])\n",
    "        \n",
    "        current_pitches = list(filter(lambda x: check_correction_pitch(current_corrections, i/100, x), current_pitches))\n",
    "        \n",
    "        try:\n",
    "            best_estimate[i] = median(current_pitches)\n",
    "        except:\n",
    "            print(\"No pitches for time:\", i/100)\n",
    "#             print(old_pitches)        \n",
    "    \n",
    "    return (np.arange(0, time), best_estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_statistics (current_collections, collection, part, debug=False):\n",
    "    pitch_estimates = []\n",
    "    time = len(current_collections[collection]['boersma'][part][0])\n",
    "\n",
    "      \n",
    "    full_collection = match_dir(correction_dir, collection)\n",
    "    full_part = match_dir(os.path.join(correction_dir, full_collection), part)\n",
    "    current_corrections = load_corrections(os.path.join(correction_dir, \n",
    "                                                            full_collection, \n",
    "                                                            full_part))\n",
    "    \n",
    "    for algo in algorithms:\n",
    "        if part in current_collections[collection][algo]:\n",
    "            if algo == 'crepe':\n",
    "                crepe_pitches = current_collections[collection][algo][part][1]\n",
    "                for i in range(len(crepe_pitches)):\n",
    "                    if check_correction_box(current_corrections, i/100):\n",
    "                        crepe_pitches[i] = -1\n",
    "                pitch_estimates.append(crepe_pitches)\n",
    "                if len(crepe_pitches) < time:\n",
    "                    time = len(crepe_pitches)\n",
    "            else:    \n",
    "                pitch_estimates.append(current_collections[collection][algo][part][1])\n",
    "                if len(current_collections[collection][algo][part][0]) < time:\n",
    "                    time = len(current_collections[collection][algo][part][0])\n",
    "      \n",
    "    pitch_estimates = np.array([pitch_estimate[:time] for pitch_estimate in pitch_estimates])\n",
    "    current_mean = find_mean(pitch_estimates)\n",
    "    current_median = find_median(pitch_estimates)\n",
    "    current_std = find_std(pitch_estimates)\n",
    "    print(\"Finding mad\")\n",
    "    current_mad = find_mad(pitch_estimates)\n",
    "\n",
    "    \n",
    "    if debug:\n",
    "        print(pitch_estimates[:,6393:6407])\n",
    "    \n",
    "    return current_mean, current_median, current_std, current_mad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scherbaum Mshavanadze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "collections = {\n",
    "    \"GVM009\": {},\n",
    "    \"GVM017\": {},\n",
    "    \"GVM019\": {},\n",
    "    \"GVM031\": {},\n",
    "    \"GVM097\": {}\n",
    "}\n",
    "\n",
    "algorithms = ['boersma', 'crepe', 'hermes', 'noll', 'yin']\n",
    "data_dir = '/Akamai/voice/data/pitches-vuv-crepe-assisted/'\n",
    "cdata_dir = '/Akamai/voice/data/pitches-postprocessed/'\n",
    "\n",
    "for collection in collections:\n",
    "    for algo in algorithms:\n",
    "        collections[collection][algo] = {}\n",
    "\n",
    "for algorithm in os.listdir(data_dir):\n",
    "    if not algorithm in algorithms:\n",
    "        continue\n",
    "    for collection in os.listdir(f\"{data_dir}{algorithm}\"):\n",
    "        if collection != 'Scherbaum Mshavanadze':\n",
    "            continue\n",
    "        for song in os.listdir(f\"{data_dir}{algorithm}/{collection}\"):\n",
    "            for part in os.listdir(f\"{data_dir}{algorithm}/{collection}/{song}\"):\n",
    "                if \"shifted\" in part: continue\n",
    "                print(part)\n",
    "                cur_data_dir = cdata_dir if algorithm == 'crepe' else data_dir\n",
    "\n",
    "                if part[:6] in collections:\n",
    "                    if 'AHDS' in part:\n",
    "                        x, y = separate(f\"{cur_data_dir}{algorithm}/{collection}/{song}/{part}\")\n",
    "                        if 'crepe' in algorithm:\n",
    "                            collections[part[:6]][algorithm][part[part.index('AHDS'):part.index('AHDS')+6]] = (x, y)\n",
    "                    elif 'ALRX' in part:\n",
    "                        x, y = separate(f\"{cur_data_dir}{algorithm}/{collection}/{song}/{part}\")\n",
    "                        collections[part[:6]][algorithm][part[part.index('ALRX'):part.index('ALRX')+6]] = (x, y)\n",
    "                    elif 'AOLS' in part:\n",
    "                        x, y = separate(f\"{cur_data_dir}{algorithm}/{collection}/{song}/{part}\")\n",
    "                        collections[part[:6]][algorithm][part[part.index('AOLS'):part.index('AOLS')+6]] = (x, y)\n",
    "                    elif 'VSOA' in part:\n",
    "                        x, y = separate(f\"{cur_data_dir}{algorithm}/{collection}/{song}/{part}\")\n",
    "                        collections[part[:6]][algorithm][part[part.index('VSOA'):part.index('VSOA')+6]] = (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = ['AHDS1M', 'AHDS2M', 'AHDS3M', 'ALRX1M', 'ALRX2M', 'ALRX3M', 'VSOAX4', 'AOLS5S']\n",
    "\n",
    "res_dir = '/Akamai/voice/html/georgian/data/ground-estimate/Scherbaum Mshavanadze/'\n",
    "std_dir = '/Akamai/voice/html/georgian/data/ground-estimate-statistics/standard-deviation/Scherbaum Mshavanadze/'\n",
    "mean_dir = '/Akamai/voice/html/georgian/data/ground-estimate-statistics/mean/Scherbaum Mshavanadze/'\n",
    "med_dir = '/Akamai/voice/html/georgian/data/ground-estimate-statistics/median/Scherbaum Mshavanadze/'\n",
    "mad_dir = '/Akamai/voice/html/georgian/data/ground-estimate-statistics/mad/Scherbaum Mshavanadze/'\n",
    "\n",
    "correction_dir = os.path.join(parent_correction_dir, 'Scherbaum Mshavanadze')\n",
    "\n",
    "for collection in collections:\n",
    "    for part in parts:\n",
    "        if not part in collections[collection]['boersma']:\n",
    "            print(f\"{part} not found in boermsa. Skipping this voice type.\")\n",
    "            continue\n",
    "        \n",
    "        t, estimate = find_optimal_pitch(collections, collection, part)\n",
    "        cmean, cmed, cstd, cmad = find_statistics(collections, collection, part)\n",
    "        \n",
    "        if not os.path.isdir(res_dir + collection):\n",
    "            os.mkdir(res_dir + collection)\n",
    "        if not os.path.isdir(std_dir + collection):\n",
    "            os.mkdir(std_dir + collection)\n",
    "        if not os.path.isdir(med_dir + collection):\n",
    "            os.mkdir(med_dir + collection)\n",
    "        if not os.path.isdir(mean_dir + collection):\n",
    "            os.mkdir(mean_dir + collection)\n",
    "        if not os.path.isdir(mad_dir + collection):\n",
    "            os.mkdir(mad_dir + collection)\n",
    "            \n",
    "        # pitch estimate\n",
    "        np.savetxt(res_dir + collection + '/' + part + '.txt', np.c_[t, estimate], delimiter=' ', fmt='%f')\n",
    "        # std\n",
    "        np.savetxt(std_dir + collection + '/' + part + '.txt', np.c_[t, cstd], delimiter=' ', fmt='%f')\n",
    "        # median\n",
    "        np.savetxt(med_dir + collection + '/' + part + '.txt', np.c_[t, cmed], delimiter=' ', fmt='%f')\n",
    "        # mean\n",
    "        np.savetxt(mean_dir + collection + '/' + part + '.txt', np.c_[t, cmean], delimiter=' ', fmt='%f')\n",
    "        # mad\n",
    "        np.savetxt(mad_dir + collection + '/' + part + '.txt', np.c_[t, cmad], delimiter=' ', fmt='%f')\n",
    "\n",
    "        print(f\"{part}:{collection} done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teach Yourself Megrelian Songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "collections2 = {\n",
    "    \"Ak'a Si Rekisho\": {},\n",
    "    'Gepshvat Ghvini': {},\n",
    "    'Io _ Chkin Kiana': {},\n",
    "    'Mesishi Vardi': {},\n",
    "    'Meureme': {},\n",
    "    'Mi Re Sotsodali_': {},\n",
    "    \"Mole Chit'i Gilakhe\": {},\n",
    "    'O Da': {},\n",
    "    'Vojanudi Chkim Jargvals': {}\n",
    "}\n",
    "\n",
    "algorithms = ['boersma', 'crepe', 'hermes', 'yin', 'noll']\n",
    "data_dir = '/Akamai/voice/data/pitches-vuv-crepe-assisted/'\n",
    "cdata_dir = '/Akamai/voice/data/pitches-postprocessed/'\n",
    "\n",
    "\n",
    "for collection in collections2:\n",
    "    for algo in algorithms:\n",
    "        collections2[collection][algo] = {}\n",
    "\n",
    "def root_name (name):\n",
    "    s = None; e = None\n",
    "    for i in range(len(name)-2, 0, -1):\n",
    "        if name[i] == '.': e = i;\n",
    "        elif name[i:i+2] == '_A': \n",
    "            s = i\n",
    "            break\n",
    "    if s == None: return name[:e];\n",
    "    else: return name[:s];\n",
    "\n",
    "for algorithm in os.listdir(data_dir):\n",
    "    if not algorithm in algorithms:\n",
    "        continue\n",
    "    for collection in os.listdir(f\"{data_dir}{algorithm}\"):\n",
    "        if collection != 'Teach Yourself Megrelian Songs':\n",
    "            continue\n",
    "        for song in os.listdir(f\"{data_dir}{algorithm}/{collection}\"):\n",
    "            for part in os.listdir(f\"{data_dir}{algorithm}/{collection}/{song}\"):\n",
    "                if \"shifted\" in part: continue\n",
    "                print(part)\n",
    "                if root_name(part) in collections2:\n",
    "                    cur_data_dir = cdata_dir if algorithm == 'crepe' else data_dir\n",
    "                    if 'AHDS' in part:\n",
    "                        x, y = separate(f\"{cur_data_dir}{algorithm}/{collection}/{song}/{part}\")\n",
    "                        collections2[root_name(part)][algorithm][part[part.index('AHDS'):part.index('AHDS')+6]] = (x, y)\n",
    "                    else:\n",
    "                        x, y = separate(f\"{cur_data_dir}{algorithm}/{collection}/{song}/{part}\")\n",
    "                        collections2[root_name(part)][algorithm]['VSOAX4'] = (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = ['AHDS1M', 'AHDS2M', 'AHDS3M', 'VSOAX4']\n",
    "\n",
    "res_dir = '/Akamai/voice/html/georgian/data/ground-estimate/Teach Yourself Megrelian Songs/'\n",
    "std_dir = '/Akamai/voice/html/georgian/data/ground-estimate-statistics/standard-deviation/Teach Yourself Megrelian Songs/'\n",
    "med_dir = '/Akamai/voice/html/georgian/data/ground-estimate-statistics/median/Teach Yourself Megrelian Songs/'\n",
    "mean_dir = '/Akamai/voice/html/georgian/data/ground-estimate-statistics/mean/Teach Yourself Megrelian Songs/'\n",
    "mad_dir = '/Akamai/voice/html/georgian/data/ground-estimate-statistics/mad/Teach Yourself Megrelian Songs/'\n",
    "\n",
    "\n",
    "correction_dir = os.path.join(parent_correction_dir, 'Teach Yourself Megrelian Songs')\n",
    "\n",
    "\n",
    "for collection in collections2:\n",
    "    for part in parts:\n",
    "        if not part in collections2[collection]['boersma']:\n",
    "            print(f\"{part} not found in boermsa. Skipping this voice type.\")\n",
    "            continue\n",
    "\n",
    "        \n",
    "        t, estimate = find_optimal_pitch(collections2, collection, part)\n",
    "        cmean, cmed, cstd, cmad = find_statistics(collections2, collection, part)\n",
    "\n",
    "        if not os.path.isdir(res_dir + collection):\n",
    "            os.mkdir(res_dir + collection)\n",
    "        if not os.path.isdir(std_dir + collection):\n",
    "            os.mkdir(std_dir + collection)\n",
    "        if not os.path.isdir(med_dir + collection):\n",
    "            os.mkdir(med_dir + collection)\n",
    "        if not os.path.isdir(mean_dir + collection):\n",
    "            os.mkdir(mean_dir + collection)\n",
    "        if not os.path.isdir(mad_dir + collection):\n",
    "            os.mkdir(mad_dir + collection)\n",
    "\n",
    "        # pitch estimate\n",
    "        np.savetxt(res_dir + collection + '/' + part + '.txt', np.c_[t, estimate], delimiter=' ', fmt='%f')\n",
    "        # std\n",
    "        np.savetxt(std_dir + collection + '/' + part + '.txt', np.c_[t, cstd], delimiter=' ', fmt='%f')\n",
    "        # median\n",
    "        np.savetxt(med_dir + collection + '/' + part + '.txt', np.c_[t, cmed], delimiter=' ', fmt='%f')\n",
    "        # mean\n",
    "        np.savetxt(mean_dir + collection + '/' + part + '.txt', np.c_[t, cmean], delimiter=' ', fmt='%f')\n",
    "        # mad\n",
    "        np.savetxt(mad_dir + collection + '/' + part + '.txt', np.c_[t, cmad], delimiter=' ', fmt='%f')\n",
    "\n",
    "        print(f\"{part}:{collection} done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teach Yourself Gurian Songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "collections3_test = {\"Sabodisho\": {}}\n",
    "collections3 = {\n",
    "    \"Adila-Alipasha\": {},\n",
    "    \"Indi-Mindi\": {},\n",
    "    'Mival Guriashi (1)': {} ,\n",
    "    'Pikris Simghera': {},\n",
    "    \"Alaverdi\": {},\n",
    "    \"K'alos Khelkhvavi\": {},\n",
    "    'Mival Guriashi (2)' : {}, \n",
    "    \"Sabodisho\": {},\n",
    "    \"Khasanbegura\": {},     \n",
    "    \"Mok'le Mravalzhamieri\": {},\n",
    "    'Sadats Vshobilvar': {},\n",
    "    \"Beri Ak'vans Epareba\": {}, \n",
    "    \"Lat'aris Simghera\": {},    \n",
    "    \"Mts'vanesa Da Ukudosa\": {}, \n",
    "    \"Shermanduli\": {},\n",
    "    \"Brevalo\": {},             \n",
    "    \"Manana\": {},         \n",
    "    'Nanina (1)': {},      \n",
    "    \"Shvidk'atsa\": {},\n",
    "    \"Chven-Mshvidoba\": {},    \n",
    "    \"Maq'ruli\": {},               \n",
    "    'Nanina (2)': {},          \n",
    "    'Supris Khelkhvavi': {},\n",
    "    'Didi Khnidan': {},     \n",
    "    \"Masp'indzelsa Mkhiarulsa\": {}, \n",
    "    \"Orira\": {},                \n",
    "    \"Ts'amok'ruli\": {},\n",
    "    \"Gakhsovs, T'urpa\": {},\n",
    "    \"Me-Rustveli\": {},        \n",
    "    \"P'at'ara Saq'varelo\": {}\n",
    "}\n",
    "\n",
    "algorithms = ['boersma', 'crepe', 'hermes', 'yin', 'noll']\n",
    "data_dir = '/Akamai/voice/data/pitches-vuv-crepe-assisted/'\n",
    "cdata_dir = '/Akamai/voice/data/pitches-postprocessed/'\n",
    "working_song=''\n",
    "\n",
    "colls=collections3\n",
    "for collection in colls:\n",
    "    for algo in algorithms:\n",
    "        colls[collection][algo] = {}\n",
    "\n",
    "def root_name (name):\n",
    "    s = None; e = None\n",
    "    for i in range(len(name)-2, 0, -1):\n",
    "        if name[i] == '.': e = i;\n",
    "        elif name[i:i+2] == '_A': \n",
    "            s = i\n",
    "            break\n",
    "    \n",
    "    if s == None: return name[:e];\n",
    "    else: return name[:s];\n",
    "\n",
    "for algorithm in os.listdir(data_dir):\n",
    "    if not algorithm in algorithms:\n",
    "        continue\n",
    "    for collection in os.listdir(f\"{data_dir}{algorithm}\"):\n",
    "        if collection != 'Teach Yourself Gurian Songs':\n",
    "            continue\n",
    "        for song in os.listdir(f\"{data_dir}{algorithm}/{collection}\"):\n",
    "            if song != working_song and working_song != \"\":\n",
    "                continue\n",
    "            for part in os.listdir(f\"{data_dir}{algorithm}/{collection}/{song}\"):\n",
    "                if \"shifted\" in part: continue\n",
    "                print(part)\n",
    "                if root_name(part) in colls:\n",
    "                    cur_data_dir = cdata_dir if algorithm == 'crepe' else data_dir\n",
    "                    if 'AHDS' in part:\n",
    "                        x, y = separate(f\"{cur_data_dir}{algorithm}/{collection}/{song}/{part}\")\n",
    "                        colls[root_name(part)][algorithm][part[part.index('AHDS'):part.index('AHDS')+6]] = (x, y)\n",
    "                    else:\n",
    "                        x, y = separate(f\"{cur_data_dir}{algorithm}/{collection}/{song}/{part}\")\n",
    "                        colls[root_name(part)][algorithm]['VSOAX4'] = (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = ['AHDS1M', 'AHDS2M', 'AHDS3M', 'VSOAX4']\n",
    "\n",
    "res_dir = '/Akamai/voice/html/georgian/data/ground-estimate/Teach Yourself Gurian Songs/'\n",
    "mean_dir = '/Akamai/voice/html/georgian/data/ground-estimate-statistics/mean/Teach Yourself Gurian Songs/'\n",
    "std_dir = '/Akamai/voice/html/georgian/data/ground-estimate-statistics/standard-deviation/Teach Yourself Gurian Songs/'\n",
    "med_dir = '/Akamai/voice/html/georgian/data/ground-estimate-statistics/median/Teach Yourself Gurian Songs/'\n",
    "mad_dir = '/Akamai/voice/html/georgian/data/ground-estimate-statistics/mad/Teach Yourself Gurian Songs/'\n",
    "correction_dir = os.path.join(parent_correction_dir, 'Teach Yourself Gurian Songs')\n",
    "\n",
    "\n",
    "for collection in colls:\n",
    "    for part in parts:\n",
    "        if not part in colls[collection]['boersma']:\n",
    "            print(f\"{part} not found in boermsa. Skipping this voice type.\")\n",
    "            continue\n",
    "\n",
    "        t, estimate = find_optimal_pitch(colls, collection, part)\n",
    "        cmean, cmed, cstd, cmad = find_statistics(colls, collection, part)\n",
    "\n",
    "        if not os.path.isdir(res_dir + collection):\n",
    "            os.mkdir(res_dir + collection)\n",
    "        if not os.path.isdir(std_dir + collection):\n",
    "            os.mkdir(std_dir + collection)\n",
    "        if not os.path.isdir(med_dir + collection):\n",
    "            os.mkdir(med_dir + collection)\n",
    "        if not os.path.isdir(mean_dir + collection):\n",
    "            os.mkdir(mean_dir + collection)\n",
    "        if not os.path.isdir(mad_dir + collection):\n",
    "            os.mkdir(mad_dir + collection)\n",
    "            \n",
    "\n",
    "        # pitch estimate\n",
    "        np.savetxt(res_dir + collection + '/' + part + '.txt', np.c_[t, estimate], delimiter=' ', fmt='%f')\n",
    "        # std\n",
    "        np.savetxt(std_dir + collection + '/' + part + '.txt', np.c_[t, cstd], delimiter=' ', fmt='%f')\n",
    "        # median\n",
    "        np.savetxt(med_dir + collection + '/' + part + '.txt', np.c_[t, cmed], delimiter=' ', fmt='%f')\n",
    "        # mean\n",
    "        np.savetxt(mean_dir + collection + '/' + part + '.txt', np.c_[t, cmean], delimiter=' ', fmt='%f')\n",
    "        # mad\n",
    "        np.savetxt(mad_dir + collection + '/' + part + '.txt', np.c_[t, cmad], delimiter=' ', fmt='%f')\n",
    "\n",
    "        print(f\"{part}:{collection} done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing and Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Akamai/voice/html/georgian/data/ground-estimate-statistics/'\n",
    "for a in os.listdir(os.path.join(data_dir, 'mean')):\n",
    "    if not a.startswith('.'):\n",
    "        for b in os.listdir(os.path.join(data_dir, 'mean', a)):\n",
    "            for c in os.listdir(os.path.join(data_dir, 'mean', a, b)):\n",
    "                os.rmdir(os.path.join(data_dir, 'mad', a, b, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = collections3[\"Lat'aris Simghera\"]['crepe']['AHDS1M'][1]\n",
    "print(len(a[a < 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0, 0, 1.5, 1.6, 2])\n",
    "median_absolute_deviation(a)*1.4826"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
